<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[用OPENWRT路由器抓包网络流量笔记]]></title>
    <url>%2Fopenwrt-wireshark-setting%2F</url>
    <content type="text"><![CDATA[前言openwrt是一款基于linux的路由器系统，可以安装很多相关的工具包，完成像linux系统服务器可以完成的工作，比如今天我们要讲的路由器的网络数据包抓包。环境安装了openwrt的路由器，ip地址：192.168.10.1要抓包流量的Android手机，ip地址：192.68.10.235工作台笔记本，ip地址：192.168.10.234安装与配置以下介绍两种方法都可以实现路由器数据包抓取的功能简单的说明根据openwrt文档，所有的局域网的数据最后都是通过br-lan虚拟网卡来做转发，所以对此网卡进行监控即可此命令本质是远程在路由器上执行网络监控命令，输入文本到本机的wireshark里面使用wireshark作为可视化工具来查看捕获与tcpdump的通信Tcpdump可以安装在OpenWrt路由器上。因此，这种方法消除了让远程Wireshark或类似听众实时分析流量的需要。ssh登陆到openwrt(默认端口：22)，更新并安装tcpdump12opkg updateopkg install tcpdump执行以下命令在接口（-i）上侦听并将捕获的信息存储到文件（-w），并在执行此操作时（-v）进行冗长操作。1tcpdump -i any -v -w pcap.cap生成的pcap.cap文件，我们可以传回工作台，用wireshark打开做进一步的分析以下是一些使用tcpdump的例子：https://www.rationallyparanoid.com/articles/tcpdump.html制作一键命令脚本命令格式如下：1ssh -p ssh端口 -o StrictHostKeyChecking=no ssh用户名@ssh地址 &apos;tcpdump -s 0 -U -n -w - -i br-lan not port ssh端口&apos; | wireshark -k -i -由于我环境配置了不用密码登陆的方式所以我们可以直接写成如下：12ssh openwrt &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; | wireshark -k -i -ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; | wireshark -k -i -前面讲述了基本的原理和操作手段，但是缺点是每次都需要输入长串命令行和密码，可以利用linux的一些小操作技巧，简化此过程，做成一个命令工具，方便随时调用。基本原理：使用 sshpass 工具来做密码输入使用 alias 别名来做成命令语句在工作台安装sshpass，执行以下脚本：12sudo pacman -S sshpasssshpass -p &apos;password&apos; ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; | wireshark-gtk -k -i -把执行语句写到.bash_rc就可以一条命令执行抓包分析了1alias tsharkbyopenwrt=&quot;sshpass -p &apos;password&apos; ssh -p 22 -o StrictHostKeyChecking=no root@192.168.10.1 &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; | wireshark-gtk -k -i -&quot;完善脚本通过命名管道来导回数据12mkfifo /tmp/fifosshpass -p &apos;passwrod&apos; ssh openwrt &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; &gt; /tmp/fifo &amp; wireshark-gtk -k -i /tmp/fifo这里我配置了.ssh/config，所以可以直接使用ssh openwrt命令代替前面指定端口与用户名的方式。我们还有一个方法可以不用安装sshpass,直接使用密钥的方式来登陆路由器抓包,以上就可以写为：12ssh-copy-id openwrtssh openwrt &apos;tcpdump -s 0 -U -n -w - -i br-lan not port 22&apos; &gt; /tmp/fifo &amp; wireshark-gtk -k -i /tmp/fifo使用远程Wireshark侦听器进行分析ssh登陆到openwrt(默认端口：22)，更新并安装iptables-mod-tee12opkg update opkg install iptables-mod-tee运行以下iptables命令以“在输出接口（-o）上将源IP（-s）的每个数据包的副本转发到网关IP（ - 网关）”1iptables -A POSTROUTING -t mangle -o br-lan ! -s 192.168.10.235 -j TEE --gateway 192.168.10.234运行以下iptables命令以“在接口（-i）上将目的IP（-d）的每个数据包的副本转发到网关IP（ - 网关）”1iptables -A PREROUTING -t mangle -i br-lan ! -d 192.168.10.235 -j TEE --gateway 192.168.10.234在Wireshark上开始捕获流量并应用下面的过滤器：1(ip.src == 192.168.9.121) || (ip.dst == 192.168.9.121)关于iptable规则一些有用的资源：https://wiki.openwrt.org/doc/howto/netfilterhttp://www.faqs.org/docs/iptables/index.htmlhttp://ipset.netfilter.org/iptables-extensions.man.html#lbDW安装使用CloudSharkCloudShark是一个独立的，与LEDE无关的云分析平台。它依靠cshark插件远程发送数据包进行分析。请检查您的内部规则，是否允许将网络流量发送到云平台。12opkg updateopkg install cshark luci-app-cshark请查看Cloud Shark文档以获取更多信息。问题处理在工作台使用wireshark-gtk的时候报错：1Couldn&apos;t run /usr/bin/dumpcap in child process: Permission denied这是由于dumpcap这个的权限问题。12ll /usr/bin/dumpcap :(-rwxr-xr-- 1 root wireshark 102K May 23 06:39 /usr/bin/dumpcap只要把当前用户加入到wireshark用户组里，重启就ok了（暂时不明为什么一定要重启，反正我是重启以后才正常使用的)。12sudo usermod -aG wireshark $LOGNAMEsudo setcap cap_net_raw,cap_net_admin+eip /usr/bin/dumpcapsetcat对应使用getcap查看当前的方法权限参考ANALYZING NETWORK TRAFFIC WITH OPENWRTHow to capture, filter and inspect packetsGETTING STARTED WITH OPENWRT – LINUXFYING ROUTERS]]></content>
      <tags>
        <tag>openwrt</tag>
        <tag>wireshark</tag>
        <tag>cloudshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UEFI+GPT安装Archlinux与Win10双系统教程]]></title>
    <url>%2Farchlinux-uefi-bootloader%2F</url>
    <content type="text"><![CDATA[前言最近新入手一台Thinkpad,使用UEFI+GPT预安装好了Win10操作系统，准备开始安装Archlinux。如果你准备在一块新硬盘上安装双系统，那么应该先安装windows。如果你安装的是Win10，那么它应该默认就是按UEFI+GPT方式安装的，可以按Win+X键打开磁盘管理，如果是UEFI安装的，那么应该有一个EFI分区，可能是250M。其它还有Windows的恢复分区和基本数据分区。不用管恢复分区，如果现在磁盘上没有剩余空间，可以右键点击基本数据分区，点击压缩卷，给Arch的安装腾出空间。用右键点击磁盘，查看属性，可以知道自己是否采用了GPT分区方式。在安装之前，请在电源计划中关掉Windows的快速启动，并在BIOS中关掉Secure Boot，可以很容易搜到对应自己电脑的具体方法。如果上面有哪一条没有满足，请只看一看我遇到的问题，具体安装请再参考其它教程安装安装之前准备一个大于4G的U盘安装镜像，可以从Arch Linux的官方网站下载制作U盘启动盘这里我只介绍linux系统下使用dd的方式，windows下面的方法可以看一下这个安装教程插入U盘，查看U盘设备名,不需求挂载12lsblksudo dd if=archlinux-2018.06.01-x86_64.iso of=/dev/sdb这样，就制作好了U盘启动了，把U盘插入要安装的机子，配置BIOS通过U盘启动，就可以进入光盘引导的临时系统。选择镜像源Arch Linux是通过网络进行安装的，为了以更快的速度下载软件包，建议先配置镜像源。配置镜像源的方法是编辑/etc/pacman.d/mirrorlist这个文件，将想用的镜像源的放到第一个非井号开头的行即可。如下可将中科大镜像源作为首选镜像源。12345678# /etc/pacman.d/mirrorlist# This is the USTC mirrorServer = http://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch# and other mirrors## Score: 4.6, ChinaServer = http://mirrors.163.com/archlinux/$repo/os/$arch#配置完成后可以执行pacman -Syy试一下，可以看一下pacman从镜像站下载文件的速度。分区我们前面提过已经默认有安装的Win10系统,使用fdisk可以看到已经有一个EFI分区为250M大小。因此不要单独为Linux分出EFI分区，因为要双系统启动的话应该把Win10的EFI分区挂载到/boot上。以下是我的硬盘分区情况,因为我还有一块硬盘用来挂载/home，所以我只要创建根分区和swap分区1234567Device Start End Sectors Size Type/dev/nvme0n1p1 2048 534527 532480 260M EFI System/dev/nvme0n1p2 534528 567295 32768 16M Microsoft reserved/dev/nvme0n1p3 567296 254337023 253769728 121G Microsoft basic data/dev/nvme0n1p4 254337024 485023743 230686720 110G Linux filesystem/dev/nvme0n1p5 498069504 500117503 2048000 1000M Windows recovery environment/dev/nvme0n1p6 485023744 497606655 12582912 6G Linux swap格式化1234mkfs.ext4 /dev/nvme0n1p4mkswap /dev/nvme0n1p6swapon /dev/nvme0n1p6挂载分区首先，一定是先挂载/分区，再挂载其它分区。因为要使用双系统启动，所以即使没有分/boot分区，还是应该把windows的EFI分区挂载到/上。123mount /dev/nvme0n1p4 /mnt/mkdir -p /mnt/bootmount /dev/nvme0n1p1 /mnt/boot基本软件安装安装Arch Linux的软件很简单，执行下面这条命令就行了：1pacstrap /mnt base base-devel配置系统创建fstab生成一个fstab文件（使用-U或-L分别由UUID或标签定义）：1genfstab -U /mnt &gt;&gt; /mnt/etc/fstab切换新系统现在我们执行arch-chroot /mnt，这样就以chroot的方式进入了新的系统。配置时间12ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimehwclock --systohc配置本地化在/etc/locale.gen中取消注释en_US.UTF-8 UTF-8和其他所需的本地化，并使用local-gen更新本地语言编码设置主机名1echo &apos;hcaijin.com&apos; &gt; /etc/hostname设置root密码1passwd设置启动按照上面的步骤，efi分区应该被挂载到了/boot目录下。这时，我们使用bootctl install命令，安装bootloader，然后用cp /usr/share/systemd/bootctl/arch.conf /boot/loader/entries/把示例文件复制过来，只要修改它的options部分就可以了。以我的/boot分区为例，用blkid -s PARTUUID -o value /dev/nvme0n1p1就可以生成所需要的PARTUUID，最后加上rw就行了。格式大概为：1234title Arch Linuxlinux /vmlinuz-linuxinitrd /initramfs-linux.imgoptions root=UUID=6278bd34-44cd-41b9-9bdd-239d9ce4020a rw意思是创建一个标题为Arch Linux的启动项，它用bootloader所在分区(/dev/sda1)根目录下的vmlinuz-linux作为Linux内核，initramfs-linux.img作为initramfs镜像(可以认为是一个临时rootfs镜像)，并且用root=/dev/sda2 ro作为内核参数。再编辑/boot/loader/loader.conf.12timeout 3default arch意思是默认用arch.conf的配置启动，等待3秒没有键盘操作即使用默认配置启动。新系统的网络启动盘中默认配置好了有关网络的软件，但新的系统中却没有。如果你只是使用单一且固定的有线网络，使用systemctl enable dhcpcd@interface.service就可以了（interface是你的网络接口名，可以使用ip link查看，类似enp3s0）。如果要使用无线网络，那么就要使用pacman -S iw wpa_supplicant dialog命令安装这些软件包。如果失败，可能要安装固件。至此，新系统的配置就完成了。使用exit命令退出chroot环境，umount -R /mnt卸载挂载的分区，然后使用reboot重启一下就好了。最后可能会启动失败，解决方法是进入BIOS里的设置把UEFI作为唯一的启动方式。然后保存退出，就可以看到有三个启动项（分别是Arch Linux, Windows Manage, Default），选择你要进入的系统就可以了。]]></content>
      <tags>
        <tag>archlinux</tag>
        <tag>windows</tag>
        <tag>uefi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chromium OS源码编译、U盘安装及使用笔记]]></title>
    <url>%2Fchromium-os-install%2F</url>
    <content type="text"><![CDATA[根据官方文档 https://www.chromium.org/chromium-os/quick-start-guide 只有Ubuntu Trusty版本的安装方式写了个ArchLinux的安装方法安装依赖Arch Linux 4.16.12-1-ARCHx86_64 GNU/Linux有sudo权限的用户基本依赖确保有如下包就好了，没有就用pacman -S 安装就是：1sudo pacman -S git-core gitk git-gui subversion curl lvm2 thin-provisioning-tools python-pkg-resources python-virtualenv python-oauth2client安装depot_tools用git克隆下来就好了,但要注意python的版本，后面会说.12cd ~/Source/git clone https://chromium.googlesource.com/chromium/tools/depot_tools确保deport_tools目录在PATH变量里sudoers配置要设置Chrome操作系统构建环境，应该关闭sudo的tty_tickets选项，因为它与cros_sdk不兼容。执行如下操作：12345678cd /tmpcat &gt; ./sudo_editor &lt;&lt;EOF#!/bin/shecho Defaults \!tty_tickets &gt; \$1 # Entering your password in one shell affects all shells echo Defaults timestamp_timeout=180 &gt;&gt; \$1 # Time between re-requesting your password, in minutesEOFchmod +x ./sudo_editor sudo EDITOR=./sudo_editor visudo -f /etc/sudoers.d/relax_requirements获取源码创建一个目录来保存源文件“${SOURCE_REPO}”。12345678export SOURCE_REPO=&quot;~/Source/chromiumos&quot;mkdir $&#123;SOURCE_REPO&#125;cd $&#123;SOURCE_REPO&#125;virtualenv -p /usr/bin/python2 venv #这里我们要把python环境切换为2.7，才能使用下面的reporepo init -u https://chromium.googlesource.com/chromiumos/manifest.git# Optional: Make any changes to .repo/local_manifests/local_manifest.xml before syncingrepo sync创建chromiumos构建包12export BOARD=amd64-genericcros_sdk -- ./build_packages --board=$&#123;BOARD&#125;构建镜像1cros_sdk -- ./build_image --board=$&#123;BOARD&#125;烧入USB键入 sudo fdisk -l 查看插入U盘所在区域，然后执行如下操作烧录编译的系统到U盘1cros_sdk -- cros flash usb:///dev/sdd ~/chromiumos/src/build/images/amd-generic/latest/chromiumos_test_image.bin修改分区如果要使用自定义大小容量的分区构建镜像，请考虑在 build_library/legacy_disk_layout.json 中添加新的磁盘布局或使用 adjust_part。请参阅下面的帮助，123adjust_part =&apos;STATE：1G&apos; ---- 将1GB添加到状态分区adjust_part =&apos;ROOT-A：-1G&apos; ---- 从主rootfs分区中删除1GBadjust_part =&apos;STATE：= 1G&apos; --- 设置状态分区为1GB这里键入 cros_sdk -- ./build_image --board=${BOARD} --noenable_rootfs_verification test --adjust_part=&#39;STATE:+10G&#39;，这样我们的Chromium OS用户空间便增加10G，如果使用默认设置你会发现用户空间容量不足（约140MB）最后修改要安装到目标机器的bios启动项为U盘启动，插入U盘，启动。进入系统，按Ctrl + Alt + Back（F2）。在提示符下输入chronos并使用以下命令进行安装。1/usr/sbin/chromeos-install]]></content>
      <tags>
        <tag>archlinux</tag>
        <tag>ChromiumOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arch Linux 内核更新 修复无线模块rtl8821ce编译失败的问题]]></title>
    <url>%2Fkernel-upgrade-fix-rtl8821ce%2F</url>
    <content type="text"><![CDATA[最近更新系统，内核从4.15 更新到了 4.16.9发现原来的无线模块编译不通过，找不到头文件stdarg.h查看无线驱动信息通过ip l可以看到只有有线网卡123451: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: enp3s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether 8c:16:45:3f:68:0d brd ff:ff:ff:ff:ff:ff查看无线网卡驱动，找到相应的驱动去下载就好了123lspci | grep -i &apos;newwork&apos;Network controller: Realtek Semiconductor Co., Ltd. RTL8821CE 802.11ac PCIe Wireless Network Adapter下载无线驱动源码1git clone https://github.com/endlessm/linux由于这个项目特别的大，这里只需要下载drivers/net/wireless/rtl8821ce编译修改Makefile这里需要修改Makefile中TopDIR变量的值为当前路径，否则会提示错误退出12cd drivers/net/wireless/rtl8821cesed -i &apos;s/export TopDIR ?=/export TopDIR ?= $(shell pwd)/g&apos; Makefile执行make在最新的内核版本（4.16.9-1-ARCH）下编译失败，提示如下：12345678910111213graz@graz ~/Source/driver_net_wireless/rtl8821ce % make/usr/bin/make ARCH=x86_64 CROSS_COMPILE= -C /lib/modules/4.16.9-1-ARCH/build M=/home/graz/Source/driver_net_wireless/rtl8821ce modulesmake[1]: Entering directory &apos;/usr/lib/modules/4.16.9-1-ARCH/build&apos; CC [M] /home/graz/Source/driver_net_wireless/rtl8821ce/core/rtw_cmd.oIn file included from ./include/linux/list.h:9, from ./include/linux/module.h:9, from /home/graz/Source/driver_net_wireless/rtl8821ce/include/basic_types.h:81, from /home/graz/Source/driver_net_wireless/rtl8821ce/include/drv_types.h:31, from /home/graz/Source/driver_net_wireless/rtl8821ce/core/rtw_cmd.c:22:./include/linux/kernel.h:6:10: fatal error: stdarg.h: No such file or directory #include &lt;stdarg.h&gt; ^~~~~~~~~~compilation terminated.通过locate stdarg.h找到头文件 “/usr/lib/gcc/x86_64-pc-linux-gnu/8.1.0/include/stdarg.h”1ln -s /usr/lib/gcc/x86_64-pc-linux-gnu/8.1.0/include/stdarg.h include/软链接创建好后，就可以执行make编译成功安装12sudo make installmodprobe 8821ce最后，没有报错的话，通过ip l 就可以找到这个无线网卡了1234561: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: enp3s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether 8c:16:45:3f:68:0d brd ff:ff:ff:ff:ff:ff3: wlp5s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether 70:c9:4e:d8:6d:01 brd ff:ff:ff:ff:ff:ff]]></content>
      <tags>
        <tag>linux</tag>
        <tag>rtl8821ce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客系统从ghost 迁移hexo 安装与配置]]></title>
    <url>%2Fhexo-install%2F</url>
    <content type="text"><![CDATA[备份Ghost后台export，导出后是一个JSON，包含所有文章以及一些元数据：修改日期、Tags 等等图片等资源，可以到 assets 文件夹下，打包下载12cd /data/www/ghosttar -zcvf images.tag assets/content安装hexo安装依赖1pacman -S npm安装123456npm install hexo-cli -gcd /data/www/hexo init hcaijin.comcd hcaijin.comhexo installhexo server迁移导入Ghost数据12345## 安装数据转换插件npm install hexo-migrator-ghost --save## 导入数据hexo migrate ghost ghost-export.json导入图片123cp images.tag /data/www/hcaijin.com/source/cd /data/www/hcaijin.com/source/tar -zxvf images.tag最后，做一些必要的配置基本配置Hexo 配置NexT 配置NexT 高级配置安装其他插件12345npm install hexo-generator-searchdb --save npm install hexo-generator-sitemap --save npm install hexo-generator-feed --save npm install hexo-pwa --save npm install hexo-all-minifier --save]]></content>
      <tags>
        <tag>ghost</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new "My New Post"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[ghost 更新记录]]></title>
    <url>%2Fghost-upgrade%2F</url>
    <content type="text"><![CDATA[好久没有更新ghost 0.6.0，今天更新的时候发现最新版本，0.11.11 版本 更新安装的时候报错。查看error日志，是依赖的npm和node版本问题。解决方法就是要么升级npm,node，要么降级ghost到npm,node支持的版本。升级npm,node在这里就不说了，网上有很多的方法，我用的是搬瓦工家的最便宜vps，使用的npm,node不好升级，估计还得升级linux内核，我就不打算使用这个方法了。降级ghost到npm,node支持的版本。我们到Ghost各版本历史去找一下历史版本，我尝试了几个版本，最后确定0.8.0这个版本是可以正常使用的。这样我们就可以开始升级ghost了。升级ghost不需要停了当前的服务，但是，升级更新都要做好备份。备份登陆并进入https://$HOSTNAME/ghost/debug这个页面导出备份。最好能登陆到服务器进入ghost安装的目录备份一下根目录下的content，这一步要先暂停服务。12cd /data/www/ghosttar -zcvf ghost-content.tag content备份好以后，我们就可以删除与升级相关的目录了文件。1rm -rf core/ node_modules/ index.js *.json下载最新版本1curl -LOk https://github.com/TryGhost/Ghost/releases/download/0.8.0/Ghost-0.8.0.zip然后解压到/data/www/ghost12cd ~unzip -uo Ghost-0.8.0.zip -d /data/www/ghost安装并重启1npm cache clear &amp;&amp; npm install --production没有报错的话就是安装成功了。重启ghost1NODE_ENV=production pm2 start index.js --name &quot;ghost&quot;]]></content>
      <tags>
        <tag>ghost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统Chrome,Firefox程序无用使用Fcitx的问题解决方法]]></title>
    <url>%2Flinux-xi-tong-chromefirefoxcheng-xu-wu-yong-shi-yong-fcitxde-wen-ti-jie-jue-fang-fa%2F</url>
    <content type="text"><![CDATA[起因使用的gentoo有半年没有更新系统了，原来用的好好的输入法，更新完以后，在其他的程序都可以正常使用fcitx。但是，在chrome,firefox（后来知道应该是GTK,QT相关的程序用了最新版导致的问题）就是用不了，网上也有很多人提问，也没有一个有效的解决方法。环境Linux hcj-arch 4.4.39-1-lts #1 SMP Thu Dec 15 21:10:18 CET 2016 x86_64 GNU/Linufcitx version: 4.2.9.1Google Chrome 55.0.2883.87Mozilla Firefox 50.1.0检查首先保证环境变量有设置，当然，如果其他程序都可以使用，那这个应该是没有问题的123export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx主要的问题就是我们要用命令 fcitx-diagnose 查看fcitx的相关模块是不是有安装。（更无脑的方式就是把这个命令里显示为红色的信息都看一遍，把相关的模块安装上就ok了）那么，我们可以看到：== 如上图所示，缺少gtk2,gtk3相关的模块支持，导致的Chrome,Firefox等gtk软件无法使用输入法的情况 ==解决我们先看一下fcitx构建时用到的USE标记，以下可以看到，我自己设置的是默认不安装gtk支持的，所以我们要加上，有以下两种方法：可以直接在/etc/portage/make.conf USE标记上加上gtk的支持直接定义USE标记，加上gtk的支持1USE=&quot;X autostart cairo dbus enchant introspection nls pango qt4 table xml -debug gtk2 gtk3 -lua -opencc -static-libs &#123;-test&#125;&quot; sudo emerge fcitx最后，重新编译安装过fcitx以后，再看一下fcitx-diagnose，只要没有红色相关字体的警告信息，就说明已经可以正常使用了。把浏览器重启一下，如果还不行，得重启一下系统。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>chrome</tag>
        <tag>firefox</tag>
        <tag>fcitx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux挂载Mac系统下的dmg文件]]></title>
    <url>%2Flinuxgua-zai-mac-xi-tong-xia-de-dmgwen-jian%2F</url>
    <content type="text"><![CDATA[最近想在virtualbox下安装Mac系统，了解到Mac的安装镜像文件是dmg格式的，并下载到了 Install OS X Yosemite 10.10.1.dmg 安装包。解压缩本来以为Mac的安装与其他系统的类似，只要把镜像包在虚拟机中做为cd启动就可以了，然而并没什么用 - -这不，想到把dmg格式的包转化为iso的格式再在虚拟机中启动，这就有了这篇文章的问题了。google到这个工具acetoneiso可以直接把dmg格式的转为iso但是，我想是不是可以用更简单的方法来操作。现在的dmg一般都使用(zlib 或者 bzip2压缩算法)压缩过需要使用dmg2img把dmg文件转为img1$ dmg2img Install\ OS\ X\ Yosemite\ 10.10.1.dmg yosemite.img提示如，就表示成功了：Archive successfully decompressed as yosemite.img检查模块在挂载之前我们要先确保hfsplus模块启用：1lsmod | grep hfs如果没有输出，就表示模块未启用，使用如下命令启用：1modprobe hfsplus挂载启用成功后，就可以用mount挂载img，这里我挂载失败，提示存在坏道，在这里才找到了解决的方法。123456mount -t hfsplus -o loop my.img /mnt/hfsmount: wrong fs type, bad option, bad superblock on /dev/loop0, missing codepage or helper program, or other error In some cases useful info is found in syslog - try dmesg | tail or so问题处理查询系统日志在最下面提示如下信息：12dmesg | tail [2015609.436682] hfsplus: unable to find HFS+ superblock解决方案：1.先用fdisk查询img扇区可以看到它有两个设备.img1,.img22.把img的文件挂载出来就得找到开始挂载的起始扇区，所以要设置一下offset的值，这里offset=1259643×512，运行以下：1sudo mount -t hfsplus -v -o loop,offset=644937216 yosemite.img /mnt/hfs以上，就可以把镜像挂载到了目录/mnt/hfs下。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>mount</tag>
        <tag>mac</tag>
        <tag>virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea tomcat 启动web应用异常处理]]></title>
    <url>%2Fidea-tomcat-qi-dong-webying-yong-yi-chang-chu-li%2F</url>
    <content type="text"><![CDATA[1234567892016-05-11 16:36:25.799 [RMI TCP Connection(4)-127.0.0.1] ERROR org.springframework.web.context.ContextLoader - Context initialization failedorg.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;shiroFilter&apos; defined in file [/home/hcj/Work/data/ecerp-saas/Sources/ecerp/out/artifacts/ecerp_web_war_exploded/WEB-INF/classes/spring/applicationContext.xml]: Cannot resolve reference to bean &apos;securityManager&apos; while setting bean property &apos;securityManager&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityManager&apos; defined in file [/home/hcj/Work/data/ecerp-saas/Sources/ecerp/out/artifacts/ecerp_web_war_exploded/WEB-INF/classes/spring/applicationContext.xml]: Cannot resolve reference to bean &apos;shiroSubjectFactory&apos; while setting bean property &apos;subjectFactory&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;shiroSubjectFactory&apos;: Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private gy.erp.service.admin.SecurityMonitor gy.erp.shiro.ShiroSubjectFactory.securityMonitor; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityMonitor&apos; defined in class path resource [spring-domain.xml]: Cannot resolve reference to bean &apos;sessionService&apos; while setting bean property &apos;sessionService&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;sessionService&apos;: FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Invalid registry store file /data/erp.guanyisoft.com/tomcat/ecerp-web.properties, cause: Failed to create directory /data/erp.guanyisoft.com/tomcat! at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:329) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:107) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1391) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1132) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:522) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461) ~[spring-beans-3.2.0.RELEASE.jar:3.2.0.RELEASE] at org.java报错总要看异常信息，以上主要关键的地方列在这里：1;nested exception is java.lang.IllegalArgumentException: Invalid registry store file /data/erp.guanyisoft.com/tomcat/ecerp-web.properties, cause: Failed to create directory /data/erp.guanyisoft.com/tomcat!idea tomcat 在启动web应用的时候会生成一个注册dubbo服务的文件，需要指定生成路径，以前项目都是默认生成在out文件里的吧，最近，不知道什么变动，需要手工在项目配置文件application.properties 指定一下：1dubbo.registry.file = /home/hcj/Work/data/ecerp-web.properties]]></content>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 声卡驱动问题]]></title>
    <url>%2Flinux-sheng-qia-qu-dong-wen-ti%2F</url>
    <content type="text"><![CDATA[最近转Gentoo，一切安装就绪了，但是想使用youtube观看视频的时候，竟没有声音，估计又得折腾一下了。（Advanced Linux Sound Architecture，ALSA）是Linux中提供声音设备驱动的内核组件，用来代替原来的开放声音系统（Open Sound System，OSSv3）。系统环境：Linux hcj.com 4.1.15-gentoo-r1组件：alsa前提：内核已经配置支持硬件设备显示1lspci | grep -i audio安装123euse -E alsaemerge --ask --changed-use --deep @worldemerge --ask alsa-utils启动声音服务12/etc/init.d/alsasound startrc-update add alsasound boot ###声音服务设置boot级别列出设备名1cat /sys/class/sound/card*/id配置默认设备1vi ~/.asoundrc最后，别忘了重启一下。参考链接1参考链接2]]></content>
      <tags>
        <tag>linux</tag>
        <tag>alsamixer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gentoo安装RTL8723BE无线网卡驱动]]></title>
    <url>%2Fan-zhuang-rtl8723bewu-xian-wang-qia-qu-dong%2F</url>
    <content type="text"><![CDATA[新配了个ThinkPad E55c 安装Gentoo时无线网卡没能正确识别。网上查了一下是3.15内核版本之前还没有包含这个驱动，需要手动安装一下。但是我想说我安装的内核版本是4.1,而且也安装了linux-firmware固件，可是怎么就没有这个驱动呢 - - 暂时先不深究。内核版本：Kernel: x86_64 Linux 4.1.15-gentoo-r1网卡型号：RTL8723BE确认网卡型号1lspci -k | grep Network下载源码123git clone https://github.com/lwfinger/rtlwifi_new.gitcd rtlwifi_new/make &amp;&amp; make install手动加载模块12modprobe rtl8723be ## 手动加载rtl8723be模块modinfo rtl8723be ## 查看模块详情模块加载成功，使用lspci -k看一下,如果显示的是如下图说明无线网卡驱动安装成功：最后ip addr show可以看到对应的网卡设备了自启动加载模块12cat /etc/conf.d/modulesmodules=&quot;rtl8723be&quot;引用]]></content>
      <tags>
        <tag>linux</tag>
        <tag>Gentoo</tag>
        <tag>rtl8723be</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常规使用]]></title>
    <url>%2Fgitshi-yong%2F</url>
    <content type="text"><![CDATA[远程仓库有master和dev分支克隆代码1git clone &lt;git url&gt;查看所有分支1git branch --all默认有了dev和master分支，所以会看到如下三个分支master[本地主分支]origin/master[远程主分支]origin/dev[远程开发分支]==新克隆下来的代码默认master和origin/master是关联的，也就是他们的代码保持同步，但是origin/dev分支在本地没有任何的关联，所以我们无法在那里开发==创建本地关联origin/dev的分支1git checkout dev origin/dev创建本地分支dev，并且和远程origin/dev分支关联，本地dev分支的初始代码和远程的dev分支代码一样切换到dev分支进行开发1git checkout dev # 这个是切换到dev分支，然后就是常规的开发假设远程仓库只有mater分支克隆代码1git clone &lt;git url&gt;查看所有分支1git branch --all默认只有master分支，所以会看到如下两个分支master[本地主分支]origin/master[远程主分支]==新克隆下来的代码默认master和origin/master是关联的，也就是他们的代码保持同步==创建本地新的dev分支12git branch dev # 创建本地分支git branch # 查看分支这时会看到master和dev，而且master上会有一个星号这个时候dev是一个本地分支，远程仓库不知道它的存在本地分支可以不同步到远程仓库，我们可以在dev开发，然后merge到master，使用master同步代码，当然也可以同步发布dev分支发布dev分支指的是同步dev分支的代码到远程服务器1git push origin dev:dev # 这样远程仓库也有一个dev分支了在dev分支开发代码1git checkout dev # 切换到dev分支进行开发开发代码之后，我们有两个选择第一个：如果功能开发完成了，可以合并主分支12345git checkout master # 切换到主分支git merge dev # 把dev分支的更改和master合并git push # 提交主分支代码远程git checkout dev # 切换到dev远程分支git push # 提交dev分支到远程第二个：如果功能没有完成，可以直接推送1git push # 提交到dev远程分支== 注意：在分支切换之前最好先commit全部的改变，除非你真的知道自己在做什么 ==删除分支1git push origin :dev # 删除远程dev分支，危险命令哦下面两条是删除本地分支12git checkout master # 切换到master分支git branch -d dev # 删除本地dev分支progit.pdf书籍格式和语言：中文、英文、PDF、ePub下载地址：http://git-scm.com/book转载]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ss-redir 的 iptables 配置(透明代理)]]></title>
    <url>%2Fss-redir-de-iptables-pei-zhi-tou-ming-dai-li%2F</url>
    <content type="text"><![CDATA[透明代理指对客户端透明，客户端不需要进行任何设置就使用了网管设置的代理规则创建1/etc/ss-redir.json 本地监听 1080 运行ss-redir -v -c /etc/ss-redir.jsonNAT表配置脚本基本配置123456789101112131415161718192021iptables -t nat -N SHADOWSOCKS# 在 nat 表中创建新链iptables -t nat -A SHADOWSOCKS -p tcp --dport 23596 -j RETURN# 23596 是 ss 代理服务器的端口，即远程 shadowsocks 服务器提供服务的端口，如果你有多个 ip 可用,但端口一致，就设置这个iptables -t nat -A SHADOWSOCKS -d 123.456.789.111 -j RETURN# 123.456.789.111 是 ss 代理服务器的 ip, 如果你只有一个 ss服务器的 ip，却能选择不同端口,就设置此条iptables -t nat -A SHADOWSOCKS -d 0.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 169.254.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 172.16.0.0/12 -j RETURNiptables -t nat -A SHADOWSOCKS -d 192.168.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 224.0.0.0/4 -j RETURNiptables -t nat -A SHADOWSOCKS -d 240.0.0.0/4 -j RETURNiptables -t nat -A SHADOWSOCKS -p tcp -j REDIRECT --to-ports 1080# 1080 是 ss-redir 的监听端口,ss-local 和 ss-redir 的监听端口不同,配置文件不同最后是应用上面的规则,将OUTPUT出去的tcp流量全部经过SOCKS链123456789#如果是在openwrt上实现透明代理的话,使用下面被注释了的规则iptables -t nat -I PREROUTING -p tcp -j SHADOWSOCKS# 在 PREROUTING 链前插入 SHADOWSOCKS 链,使其生效在个人电脑上使用以下配置iptables -t nat -A OUTPUT -p tcp -j SHADOWSOCKS如果要过滤国内流量可以列表太长了就不列出来了！清除自定义规则清空整个链 iptables -F 链名,比如:1iptables -t nat -F SHADOWSOCKS删除指定的用户自定义链 iptables -X 链名 比如:1iptables -t nat -X SHADOWSOCKS从所选链中删除规则 iptables -D 链名 规则详情 比如:1iptables -t nat -D SHADOWSOCKS -d 223.223.192.0/255.255.240.0 -j RETURN解决DNS污染的问题1234567891011121314151617181920212223242526$ sudo pacman -S archlinuxcn/dnsmasq-china-list-git$ sudo dnsmasq-update-china-list 114####脚本如下：#!/bin/bashcase &quot;$1&quot; in 114) DNS=114.114.114.114 ;; ali) DNS=223.5.5.5 ;; cnnic) DNS=1.2.4.8 ;; baidu) DNS=180.76.76.76 ;; google) DNS=8.8.8.8 ;; *) DNS=$1esacsed -i &quot;s|^\(server.*\)/[^/]*$|\1/$DNS|&quot; /etc/dnsmasq.d/accelerated-domains.china.conf]]></content>
      <tags>
        <tag>iptables</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统挂载NTFS移动硬盘]]></title>
    <url>%2Flinuxxi-tong-gua-zai-ntfsyi-dong-ying-pan%2F</url>
    <content type="text"><![CDATA[工作中，同事之间拷贝数据的时候，由于我用的linux系统无法识别同事的NTFS移动硬盘，这才网上查了一下，原来还得安装一个软件，以下是转载的文章,记录一下。有时候做大数据量迁移时，为了快速迁移大数据，有可能在Linux服务器上临时挂载NTFS格式的移动硬盘， 一般情况下，Linux是识别不了NTFS格式移动硬盘的（需要重编译Linux核心才能，加挂NTFS分区），这时候为了能让Linux服务器能够识别NTFS的移动硬盘，就必须安装ntfs-3g（Third Generation Read/Write NTFS Driver）的包。NTFS-3G介绍NTFS-3G是一个开源项目，NTFS-3G是为Linux, Android, Mac OS X, FreeBSD, NetBSD, OpenSolaris, QNX, Haiku,和其他操作系统提供的一个稳定的，功能齐全，读写NTFS的驱动程序的。它提供了安全处理Windows XP，Windows Server 2003，Windows 2000，Windows Vista，Windows Server 2008和Windows 7操作系统下的NTFS文件系统。NTFS-3g是一个开源软件，它支持在Linux下面读写NTFS格式的分区。它非常的快速，同时也很安全。它支持Windows 2000、XP、2003和Vista，并且支持所有的符合POSIX标准的磁盘操作。 ntfs-3g的目的是为了持续的发展，各硬件平台和操作系统的用户需要可靠的互通与支持ntfs的驱动，ntfs-3g可以提供可信任的、功能丰富的高性能解决方案。经过了12年多的发展，ntfs-3g已经逐渐稳定；资料介绍官方网址：http://www.tuxera.com/，文档手册：http://www.tuxera.com/community/ntfs-3g-manual/下载地址：http://www.tuxera.com/community/ntfs-3g-download/安装解压安装NTFS-3G。12345tar -xvzf ntfs-3g_ntfsprogs-2012.1.15.tgz cd ntfs-3g_ntfsprogs-2012.1.15 ./configure make make install如果没有报错，提示安装成功，下面就可以用ntfs-3g来实现对NTFS分区的读写了配置配置挂载NTFS格式的移动硬盘首先得到NTFS分区的信息12$ sudo fdisk -l | grep NTFS/dev/sdc1 * 1 244 1955776+ 7 HPFS/NTFS设置挂载点，用如下命令实现挂载1mount -t ntfs-3g &lt;NTFS Partition&gt; &lt;Mount Point&gt;例如得到的NTFS分区信息为/dev/sdc1，挂载点设置在/mnt/usb下:123$ mount -t ntfs-3g /dev/sdc1 /mnt/usb ########## 或者直接用 #######$ ntfs-3g ntfs-3g /dev/sdc1 /mnt/usb如果想实现开机自动挂载，可以在/etc/fstab里面添加如下格式语句1&lt;NTFS Partition&gt; &lt;Mount Point&gt; ntfs-3g silent,umask=0,locale=zh_CN.utf8 0 0==这样可以实现NTFS分区里中文文件名的显示。 == 卸载分区123$ umount &lt;NTFS Partition&gt; ##### 或者 #####$ umount &lt;Mount Point&gt;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ntfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux gentoo U盘安装指南]]></title>
    <url>%2Fgentoo-upan-an-zhuang-zhi-nan%2F</url>
    <content type="text"><![CDATA[再一次捣鼓gentoo,还是遇到了相当多的麻烦，这里把安装的方法重新在blog里整理一下，跟着官方安装步骤一点点来。准备安装之前下载gentoo所需的引导镜像和系统文件压缩包下载地址：https://www.gentoo.org/downloads/主要文件：install-amd64-minimal-20160303.isoportage-latest.tar.bz2stage3-amd64-20160303.tar.bz21234$ mkdir gentoo/ &amp;&amp; cd gentoo/$ wget -c # http://mirrors.163.com/gentoo/releases/amd64/autobuilds/20160303/install-amd64-minimal-20160303.iso$ wget -c http://mirrors.163.com/gentoo/snapshots/portage-latest.tar.bz2$ wget -c http://mirrors.163.com/gentoo/releases/amd64/autobuilds/20160303/stage3-amd64-20160303.tar.bz2U盘准备插入U盘，查看U盘设备名,不需求挂载12$ lsblk$ sudo dd if=install-amd64-minimal-20160303.iso of=/dev/sdb这样，就制作好了U盘启动了，把U盘插入要安装的机子，配置BIOS通过U盘启动，就可以进入光盘引导的临时系统。开始安装配置临时系统安装gentoo最主要是先把网络配置好，这里我安装的时候遇到了个非常郁闷的问题，就是，公司的个别网段限制下载，导致我在配置网络的时候浪费了不少时间，所以最好先确认一下，你所在的网段是否可以使用wget下载文件。配置IP通常启动U盘临时系统应该可以dhcp分配到一个ip,但是我因为是公司的网络，所以最好手动配置一下123# ip addr add 192.168.3.155/24 dev enp0s25# ip route add default via 192.168.3.1 dev enp0s25# echo &quot;192.168.1.1&quot; &gt; /etc/resolv.conf配置ssh链接为了方便，最好远程链接到临时系统下，那么就得配置sshd服务。==Tip: 最新的sshd服务器默认限制root登陆，需要修改一下/etc/ssh/sshd_config配置PermitRootLogin 为 yes==12# /etc/init.d/sshd start# passwd root ####配置root用户密码以上，我们就可以到本机，使用ssh远程登陆这个U盘挂启的临时系统了安装到硬盘上系统分区fdisk123456789# fdisk -lDevice Boot Start End Sectors Size Id Type/dev/sda1 2048 6143 4096 2M ef EFI (FAT-12/16/32)/dev/sda2 6144 268287 262144 128M 83 Linux/dev/sda3 268288 17045503 16777216 8G 82 Linux swap / Solaris/dev/sda4 17045504 937703087 920657584 439G 5 Extended/dev/sda5 17047552 226762751 209715200 100G 83 Linux/dev/sda6 226764800 937703087 710938288 339G 83 Linux# fdisk /dev/sda使用fdisk分区以前有详细的说明过，在这里就不再说了。不懂的，请写看一下这个树莓派安装Gentoo Linux 1.1.3 节也可以参照 官方分区方案重新读取sda分区表:1# partx -a /dev/sda格式化分区为文件系统123# mkfs.ext2 /dev/sda2# mkfs.ext4 /dev/sda5# mkfs.ext4 /dev/sda6格式化swap分区并激活12# mkswap /dev/sda3# swapon /dev/sda3创建系统临时挂载点1234# mount /dev/sda5 /mnt/gentoo# mkdir -p /mnt/gentoo/&#123;boot,home,&#125;# mount /dev/sda2 /mnt/gentoo/boot# mount /dev/sda6 /mnt/gentoo/home设定日期和时间安装Gentoo之前，请确保日期和时间是否正确设置。错误配置的时钟可能会产生各种奇怪的错误！==主要==！！！要验证当前日期和时间，运行日期：12# dateSat Mar 5 16:26:08 UTC 2016如果时间不对，请使用 MMDDhhmmYYYY 这样的格式配置一下日期和时间1date 030516262016下载和解压相关包使用临时系统自带的links下载stage3和portage==Tip: 如果前面已经在本机下载过了可以跳过这一步==1# links https://www.gentoo.org/downloads/mirrors/或者配置代理下载：1# links -http-proxy proxy.server.com:8080 https://www.gentoo.org/downloads/mirrors/效验下载的文件效验下载的文件是否完整，打开 .DIGESTS(.asc) 相关文件对比sha512加密的是否一至。1# openssl dgst -r -sha512 stage3-amd64-20160303.tar.bz2解压stage3和portage把下载好的stage3和portage放到/mnt/gentoo目录下，进入目录解压：12# cd /mnt/gentoo/# tar xvjpf stage3-*.tar.bz2 --xattrs==注: stage3解压的文件是Gentoo的目录结构，所以要解压到临时的系统目录下,即/mnt/gentoo，方便后面进行chroot==下面解压portage，这个解压需要一点时间。1# tar jxvf portage-latest.tar.bz2 -C /mnt/gentoo/usr==注: portage-latest.tar.bz2解压的文件为系统软件目录结构,需要解压到/mnt/gentoo/usr目录下==安装基本gentoo系统配置portage make 参数配置了MAKEOPTS为cpu核心数+1配置就近的镜像地址 GETOO_MIRRORS 为厦门大学的镜像源1# cat /etc/mnt/gentoo/etc/portage/make.conf==Tip: 参数配置文件/mnt/gentoo/usr/share/portage/config/make.conf.example ==配置主要Gentoo的存储库12# mkdir /mnt/gentoo/etc/portage/repos.conf# cp /mnt/gentoo/usr/share/portage/config/repos.conf /mnt/gentoo/etc/portage/repos.conf/gentoo.conf配置chroot环境的dns只需要把livecd临时环境的resolv.conf复制到要chroot的目录里就好了，如下：1cp -L /etc/resolv.conf /mnt/gentoo/etc/挂载必要的文件系统12345# mount -t proc proc /mnt/gentoo/proc# mount --rbind /sys /mnt/gentoo/sys# mount --make-rslave /mnt/gentoo/sys# mount --rbind /dev /mnt/gentoo/dev# mount --make-rslave /mnt/gentoo/devChroot 到新的环境123# chroot /mnt/gentoo /bin/bash# source /etc/profile# export PS1=&quot;(chroot) $PS1&quot;设置主机名这不是必要的步骤12# sed -i -e &apos;s/hostname.*/hostname=&quot;hcj.com&quot;/&apos; /etc/conf.d/hostname# echo &quot;127.0.0.1 hcj.com localhost&quot; &gt; /etc/hosts配置Portage1# emerge-webrsync我在配置这个的时候报错了，按照提示删除tmestamp.x文件即可。更新portage树1# emerge --sync小内存的情况使用静默模式1# emerge --sync --quiet配置系统环境查看更新的通知12# eselect news list# eselect news read选择适合的配置12# eselect profile list# eselect profile set 3 ### 我选择的是桌面环境系统更新timezone123# ls /usr/share/zoneinfo# echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone# emerge --config sys-libs/timezone-data配置语言编码12345678910111213# nano -w /etc/locale.gen# locale-gen# eselect locale listAvailable targets for the LANG variable: [1] C [2] POSIX [3] en_US [4] en_US.iso88591 [5] en_US.utf8 [6] zh_CN.utf8 * [ ] (free form)# eselect locale set 6更新一下环境1# env-update &amp;&amp; source /etc/profile &amp;&amp; export PS1=&quot;(chroot) $PS1&quot;内核配置安装内核源码12# emerge --ask sys-kernel/gentoo-sources# genkernel --install initramfs配置fstab1cat /etc/fstab编译内核文件1genkernel all完成以上就可以在/boot目录下看到内核文件1# ls /boot/kernel* /boot/initramfs*==注: genkernel编译出的内核支持几乎所有硬件，编译需要一段很长的时间，一旦genkernel运行完成，一个包括全部模块和initrd的内核将被建立。在后面配置引导程序时我们将会用到这个内核和initrd。请记下内核和initrd的名字，因为您将在配置引导程序的时候用到他们。initrd将会在启动真正的系统前自动识别硬件（如同安装光盘一样）==安装其他软件12345678# emerge vim ### 安装vim 方便后面的配置# emerge syslog-ng ### 安装系统日志管理# rc-update add sysklogd default# emerge logrotate ### 日志格式化工具# emerge --ask sys-process/cronie ### 计划任务系统# rc-update add cronie default# emerge --ask net-misc/dhcpcd # emerge --ask sys-apps/mlocate ### 快速索引配置网络123456# cat /etc/conf.d/netconfig_enp0s25=&quot;192.168.3.155 netmask 255.255.255.0 brd 192.168.3.255&quot;routes_enp0s25=&quot;default via 192.168.3.1&quot;# ln -s /etc/init.d/net.lo /etc/init.d/net.enp0s25# rc-update add net.enp0s25 default# rc-update add sshd default配置root用户密码这是必要的，为了从新系统能进入1# passwd配置GRUB引导程序123# emerge --ask sys-boot/grub:2# grub2-install /dev/sda# grub2-mkconfig -o /boot/grub/grub.cfg最后重启一下系统12345# exit# cd# umount -l /mnt/gentoo/dev&#123;/shm,/pts,&#125;# umount /mnt/gentoo&#123;/boot,/sys,/proc,&#125;# reboot引用]]></content>
      <tags>
        <tag>linux</tag>
        <tag>Gentoo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh 服务端配置]]></title>
    <url>%2Fssh-fu-wu-duan-pei-zhi%2F</url>
    <content type="text"><![CDATA[最近，在使用U盘安装gentoo配置sshd服务端碰到了问题，记录一下ssh服务端的配置文件。关于 SSH Server 的整体设定，包含使用的 port 啦，以及使用的密码演算方式1234567891011121314Port 22 # SSH 预设使用 22 这个 port，您也可以使用多的 port ！ # 亦即重复使用 port 这个设定项目即可！Protocol 2,1 # 选择的 SSH 协议版本，可以是 1 也可以是 2 ， # 如果要同时支持两者，就必须要使用 2,1 这个分隔了！#ListenAddress 0.0.0.0 # 监听的主机适配卡！举个例子来说，如果您有两个 IP， # 分别是 192.168.0.100 及 192.168.2.20 ，那么只想要 # 开放 192.168.0.100 时，就可以写如同下面的样式：ListenAddress 192.168.0.100 # 只监听来自 192.168.0.100 这个 IP 的SSH联机。 # 如果不使用设定的话，则预设所有接口均接受 SSHPidFile /var/run/sshd.pid # 可以放置 SSHD 这个 PID 的档案！左列为默认值LoginGraceTime 600 # 当使用者连上 SSH server 之后，会出现输入密码的画面， # 在该画面中，在多久时间内没有成功连上 SSH server ， # 就断线！时间为秒！Compression yes # 是否可以使用压缩指令？当然可以啰！ 说明主机的 Private Key 放置的档案，预设使用下面的档案即可！123HostKey /etc/ssh/ssh_host_key # SSH version 1 使用的私钥HostKey /etc/ssh/ssh_host_rsa_key # SSH version 2 使用的 RSA 私钥HostKey /etc/ssh/ssh_host_dsa_key # SSH version 2 使用的 DSA 私钥关于 version 1 的一些设定！12345KeyRegenerationInterval 3600 # 由前面联机的说明可以知道， version 1 会使用 # server 的 Public Key ，那么如果这个 Public # Key 被偷的话，岂不完蛋？所以需要每隔一段时间 # 来重新建立一次！这里的时间为秒！ServerKeyBits 768 # 没错！这个就是 Server key 的长度！关于登录文件的讯息数据放置与 daemon 的名称！12345678SyslogFacility AUTH # 当有人使用 SSH 登入系统的时候，SSH会记录资 # 讯，这个信息要记录在什么 daemon name 底下？ # 预设是以 AUTH 来设定的，即是 /var/log/secure # 里面！什么？忘记了！回到 Linux 基础去翻一下 # 其它可用的 daemon name 为：DAEMON,USER,AUTH, # LOCAL0,LOCAL1,LOCAL2,LOCAL3,LOCAL4,LOCAL5,LogLevel INFO # 登录记录的等级！嘿嘿！任何讯息！ # 同样的，忘记了就回去参考！安全设定项目！极重要！登入设定部分123456789PermitRootLogin no # 是否允许 root 登入！最新版本的sshd配置默认是不允许使用root登陆的，如果要使用root登陆，要把no 改为 yes 。UserLogin no # 在 SSH 底下本来就不接受 login 这个程序的登入！StrictModes yes # 当使用者的 host key 改变之后，Server 就不接受联机， # 可以抵挡部分的木马程序！RSAAuthentication yes # 是否使用纯的 RSA 认证！？仅针对 version 1 ！PubkeyAuthentication yes # 是否允许 Public Key ？当然允许啦！只有 version 2AuthorizedKeysFile .ssh/authorized_keys # 上面这个在设定若要使用不需要密码登入的账号时，那么那个 # 账号的存放档案所在档名！认证部分123456789101112131415RhostsAuthentication no # 本机系统不止使用 .rhosts ，因为仅使用 .rhosts 太 # 不安全了，所以这里一定要设定为 no ！IgnoreRhosts yes # 是否取消使用 ~/.ssh/.rhosts 来做为认证！当然是！RhostsRSAAuthentication no # 这个选项是专门给 version 1 用的，使用 rhosts 档案在 # /etc/hosts.equiv配合 RSA 演算方式来进行认证！不要使用HostbasedAuthentication no # 这个项目与上面的项目类似，不过是给 version 2 使用的！IgnoreUserKnownHosts no # 是否忽略家目录内的 ~/.ssh/known_hosts 这个档案所记录 # 的主机内容？当然不要忽略，所以这里就是 no 啦！PasswordAuthentication yes # 密码验证当然是需要的！所以这里写 yes 啰！PermitEmptyPasswords no # 若上面那一项如果设定为 yes 的话，这一项就最好设定 # 为 no ，这个项目在是否允许以空的密码登入！当然不许！ChallengeResponseAuthentication yes # 挑战任何的密码认证！所以，任何 login.conf # 规定的认证方式，均可适用！#PAMAuthenticationViaKbdInt yes # 是否启用其它的 PAM 模块！启用这个模块将会 # 导致 PasswordAuthentication 设定失效！ 与 Kerberos 有关的参数设定！因为我们没有 Kerberos 主机，所以底下不用设定！1234#KerberosAuthentication no#KerberosOrLocalPasswd yes#KerberosTicketCleanup yes#KerberosTgtPassing no底下是有关在 X-Window 底下使用的相关设定！123X11Forwarding yes#X11DisplayOffset 10#X11UseLocalhost yes登入后的项目：123456789101112PrintMotd no # 登入后是否显示出一些信息呢？例如上次登入的时间、地点等 # 等，预设是 yes ，但是，如果为了安全，可以考虑改为 no ！PrintLastLog yes # 显示上次登入的信息！可以啊！预设也是 yes ！KeepAlive yes # 一般而言，如果设定这项目的话，那么 SSH Server 会传送 # KeepAlive 的讯息给 Client 端，以确保两者的联机正常！ # 在这个情况下，任何一端死掉后， SSH 可以立刻知道！而不会 # 有僵尸程序的发生！UsePrivilegeSeparation yes # 使用者的权限设定项目！就设定为 yes 吧！MaxStartups 10 # 同时允许几个尚未登入的联机画面？当我们连上 SSH ， # 但是尚未输入密码时，这个时候就是我们所谓的联机画面啦！ # 在这个联机画面中，为了保护主机，所以需要设定最大值， # 预设最多十个联机画面，而已经建立联机的不计算在这十个当中关于使用者抵挡的设定项目：1234DenyUsers * # 设定受抵挡的使用者名称，如果是全部的使用者，那就是全部 # 挡吧！若是部分使用者，可以将该账号填入！例如下列！DenyUsers testDenyGroups test # 与 DenyUsers 相同！仅抵挡几个群组而已！关于 SFTP 服务的设定项目！1Subsystem sftp /usr/lib/ssh/sftp-server 基本上，在您的系统中，『除非有必要，否则请不要更改 /etc/ssh/sshd_config 这个档案的设定值！』因为预设的情况下通常都是最严密的 SSH 保护了，因此，可以不需要更动他！上面的说明仅是在让大家了解每个细项的一些基本内容而已！需要注意的是最后一项，如果您不愿意开放 SFTP 的话，将最后一行批注掉即可！]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>sshd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10个很有用的 Git 命令（转）]]></title>
    <url>%2F10ge-hen-you-yong-de-git-ming-ling-zhuan%2F</url>
    <content type="text"><![CDATA[转自http://blog.sae.sina.com.cn/archives/3003这里给大家分享一些很有用的 Git 命令，其中很多用法你可能都不知道，无论你是工作在团队环境中或在您的个人项目中，这些命令将对你帮助很大，让你可以更加高效的进行项目开发，更轻松愉快的工作和生活。导出最后一次提交修改过的文件我一直在使用这个命令定期进行发送给其他人进行审查/整合。这条命令将把近期提交的修改过的文件导出到一个zip文件。1git archive -o ../updated.zip HEAD $(git diff --name-only HEAD^)导出两次提交之间修改过的文件同样，如果你需要导出两次提交之间修改过的文件，你可以用这一个。12git archive -o ../latest.zip NEW_COMMIT_ID_HERE $(git diff --name-only OLD_COMMIT_ID_HERE NEW_COMMIT_ID_HERE)克隆一个特定的远程分支如果你想从远程仓库克隆特定的一个分支，这条命令对你很有用：12345git init git remote add -t BRANCH_NAME_HERE -f origin REMOTE_REPO_URL_PATH_HERE git checkout BRANCH_NAME_HERE从无关的本地仓库应用补丁如果您需要申请从提交的一些其他不相关的创库到本地存储库，这里是一个快捷的方式：123git --git-dir=PATH_TO_OTHER_REPOSITORY_HERE/.git format-patch -k -1 --stdoutCOMMIT_HASH_ID_HERE| git am -3 -k检查您的分支变化是是否其他分支的一部分cherry 命令可以让你检查你的分支的变化是否存在于其他一些分支之中。它会显示在当前分支相对于给定的分支的修改，用+或-标志提示提交合并与否。+表示不存在，而-表示存在于给定的分支。1234git cherry -v OTHER_BRANCH_NAME_HERE #For example: to check with master branch git cherry -v master启动一个无历史的新分支有时候，你需要启动一个新的分支，同时想摒弃历史信息，例如，你想将代码放在公共领域（开源）又不想共享历史信息。1git checkout --orphan NEW_BRANCH_NAME_HERE在不切换分支的情况下从其它分支检出文件下面的命令是从其他分支获取文件，而不用切换分支。1git checkout BRANCH_NAME_HERE -- PATH_TO_FILE_IN_BRANCH_HERE忽略跟踪文件的修改如果你工作在一个团队，他们都是工作在同一个分支，你需要频繁的读取/合并文件。但是有时复位了你环境的特定配置，你必须在合并后每一次都再改一下。使用这个命令，你可以忽略更改特定的文件：1git update-index --assume-unchanged PATH_TO_FILE_HERE检查提交的修改是否发布版本的一部分这个 name-rev 命令可以告诉你提交相对于最新发布版本的位置。利用这一点，你可以检查你的变化是否发布版本的一部分。1git name-rev --name-only COMMIT_HASH_HERE使用 pull rebase 操作替代 merge如果你工作的团队正工作在同一个分支，那么你所要做的获取/合并或经常拉取。分支合并的 git 记录与合并提交时提示功能分支被并入主干。但在多个团队成员工作的同一分支的情况下，经常合并导致在日志中多个合并的消息引起混乱。所以你可以使用 pull rebase，以保持历史信息清除了无用合并的消息。1git config branch.BRANCH_NAME_HERE.rebase true此外，您可以配置一个特定的分支总是衍合：1git pull --rebase]]></content>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器配置java web服务总结]]></title>
    <url>%2Fdi-ci-pei-zhi-java-webfu-wu%2F</url>
    <content type="text"><![CDATA[首先，以前是写php的，从未接触java的开发。最近公司项目重组，被安排说去做java开发，而且要快速上手,安排培训，可是，培训的都是windows下的IDE开发配置。没办法，Google呗。这样就有了这篇东拼西奏的文章，也有自己的一些经验总结，没少碰壁，不过这里还是感谢同事的帮忙，让我对java的运行有了清晰的认识。了解java包运行原理java是编译型语言，自然少不了打包，链接，当然这些都可以用maven来管理。用maven打包，链接生成的安装包就是可以直接使用java来运行的，我们这里主要说web服务的配置，所以少不了tomcat。使用tomcat来运行web项目包，就可以在浏览器端访问，java应用服务，这就是大致的过程。安装必要的软件包安装jdk,至于安装哪个版本，视情况而定1sudo pacman -S jdk8-openjdk可以搜索一下1pacman -Ss java安装maven1sudo pacman -S maven以上安装成功了以后，我们就可以使用java, mvn 的命令了，由于我们使用的是pacman安装方法，必要的环境变量都已经默认好了，可以不需要配置，具体可以看我以前写的 Java 学习笔记1安装tomcat，同样的源里也有多个版本，视情况安装相应的版本1sudo pacman -S tomcat7tomcat 主要配置详解主要目录功能默认情況 tomcat7 安装路径为 /usr/share/tomcat7，这里罗列一下主要目录的作用：/usr/share/tomcat7： 程序的主目录，也是变量 $CATALINA_HOME 所指向的位置，在单 tomcat 实例的情況下，也是变量 $CATALINA_BASE 所指向的位置。/usr/share/tomcat7/bin： 程序的执行脚本目录conf -&gt; /etc/tomcat7： 配置文档目录，存放主要是配置信息。lib -&gt; /usr/share/java/tomcat7： 共用jar包目录，这些包即给 tomcat 使用，也能给 web 应用程序所调用。logs -&gt; /var/log/tomcat7： 日志目录，对于查找错误以及查看访问记录很有用。webapps -&gt; /var/lib/tomcat7/webapps： 默认的 web 应用程序目录，tomcat7 自带了几个示例应用。启动关闭脚本我们进入程序执行脚本目录12cd /usr/share/tomcat7 sudo ./startup.sh以上，tomcat服务就启动成功了，可以在浏览器中访问http://localhost:8080 ，如果看到 tomcat 猫即说明服务已经安装成功并且能正常运行了。1sudo ./shutdown.sh这两个脚本都是通过调用 catalina.sh 来执行的，具体自己看脚本代码。实例讲解tomcat启动java应用这里我犯了一个错误，总以为java应用之前总得有个相互调用的关系，没想到其实都已经在maven打包，安装到本地就行了，web应用配置好相应的pom.xml就可以调用maven打包，安装好的后台java应用。然后，我们开始说明代码部署过程：123456cd /data/app/ ###进入工程主目录git clone git@erp:ecerp-saas ###从erp服务器拉代码到本地cd /data/app/ecerp-saas/ ###进入代码目录git pull ###这个是同步服务器代码cd /data/app/ecerp-saas/Sources/ecerp ###进到主要工程目录mvn clean install -Dmaven.test.skip=true ###打包安装工程目录下相应的程序，这样就会编译好应用到本地用户目录下`~/.m2/`在web目录下新建目录erp.hcj.com123cd /data/www/mkdir erp.hcj.com/cd erp.hcj.com/web应用java环境变量配置12touch webconfigcat webconfig1source /data/www/erp.hcj.com/webconfig ###使用环境变量生效创建备份目录,当然这个不是必要的。123456theday=$(date +%Y%m%d)releaseDir=&quot;/data/deployment/packages/$&#123;theday&#125;&quot;if [ ! -e $releaseDir ]then mkdir -p $releaseDirfi然后，我们就可以到java应用安装目录下找packagename，把它移到备份目录1cp -fp `find ~/.m2/repository/ -name $packagename` $releaseDir/$packagename12345678910111213141516#备份数据bktime=$(date +%y%m%d%H%M)backupdir=&quot;/data/deployment/release-backup/$bktime/$(basename $srvdir)&quot;if [ ! -e $backupdir ]then mkdir -p $backupdirfirootdir=/data/www/erp.hcj.com/webrootfor files in $(ls $rootdir)do if [ $files == &quot;upload&quot; ]; then ¦ echo $files not backup else ¦ /bin/cp -rfp $rootdir/$files $backupdir fi done1234567### 删除旧应用rm -rf $rootdir/WEB-INF/*### 解压文件，在web主目录下生成webrootpackagefile=$releaseDir/$packagenametar zxf $packagefile -C /data/www/erp.hcj.com### 修改webroot的权限chown tomcat7.tomcat7 -R /data/www/erp.hcj.com/webroot以上就基本是把java打包的应用程序，安装到了tomcat的webroot目录下了，但是要使这个应用启动成功，还需要配置多实例的tomcat的配置文件server.xml12345cd /data/www/erp.hcj.commkdir -p tomcat/&#123;conf,logs,tmp,work,&#125;cp -r /etc/tomcat7/* tomcat/conf/sudo chown -R tomcat7.tomcat7 tomcat/vi server.xml主要修改如下配置：12345678### 设置tomcat环境变量export CATALINA_HOME=&quot;/usr/share/tomcat7&quot;export DUSER=&quot;tomcat7&quot;export CATALINA_BASE=&quot;/data/www/erp.hcj.com/tomcat&quot;export CATALINA_PID=&quot;$CATALINA_BASE/tomcat.pid&quot;export CATALINA_TMPDIR=&quot;$CATALINA_BASE/tmp&quot;export CATALINA_OUT=&quot;$CATALINA_BASE/logs/catalina.out&quot; export LOCKFILE=&quot;$CATALINA_BASE/tomcat.lock&quot;1234### 启动服务/bin/bash $CATALINA_HOME/bin/startup.sh### 关闭服务/bin/bash $CATALINA_HOME/bin/shutdown.sh参考]]></content>
      <tags>
        <tag>linux</tag>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 学习笔记2]]></title>
    <url>%2Fjava-xue-xi-bi-ji-2-2%2F</url>
    <content type="text"><![CDATA[镜像配置由于maven的中央仓库位于国外，速度慢，也有可能其他原因无法访问，我们可以使用国内的镜像仓库。配置镜像仓库需要修改conf/settings.xml,打开该文件修改mirror标签如下：1vim /opt/maven/conf/settings.xmlmaven仓库默认是放在用户目录的.m2隐藏目录下的 ~/.m2/repository/ 。如果需要将仓库迁移到其他目录，修改conf/settings.xml环境变量配置maven编译程序过程中可用的最大，最下内存，防止内存溢出。12MAVEN_OPTS=&quot;-Xms256m -Xmx512m&quot;export MAVEN_OPTS配置web服务一定要记得设置compressableMimeType]]></content>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 学习笔记1]]></title>
    <url>%2Fjava-xue-xi-bi-ji%2F</url>
    <content type="text"><![CDATA[以下是在Arch Linux下操作，其他发行版或操作系统不适用。Maven这个词可以翻译为“知识的积累”，也可以翻译为“专 家”或“内行”。本文将介绍Maven这一跨平台的项目管理工具。作为Apache组织中的一个颇为成功的开源项目，Maven主要服务于基于Java平台的项目构建、依赖管理和项目信息管理。无论是小型的开源类库项目，还是大型的企业级应用；无论是传统的瀑布式开发，还是流行的敏捷模式，Maven都能大显身手。安装java环境1sudo pacman -S jdk8-openjdk安装好以后可以使用如下命令：12archlinux-java help ##查看帮助archlinux-java status ##java环境状态 使用的版本信息安装maven配置maven 会被安装到/opt/maven/ 目录下1sudo pacman -S maven修改环境变量1vi ~/.bashrc这样以后，就可以使用 mvn 命令来管理java项目，如下：123cd /data/gyapp/ ###进入工作目录。(自定义) mvn archetype:generate -DgroupId=helloworld -DartifactId=helloworld -Dpackage=helloworld -Dversion=1.0-SNAPSHO打包程序执行了上面的命令会在当前工作目录生成helloworld项目目录。12cd helloworld/mvn package这个时候， maven 在 helloworld 下面建立了一个新的目录 target/ ，构建打包后的 jar 文件 helloworld-1.0-SNAPSHOT.jar 就存放在这个目录下。编译后的 class 文件放在 target/classes/ 目录下面，测试 class 文件放在 target/test-classes/ 目录下面。运行为了验证我们的程序能运行，执行下面的命令：1java -cp target/helloworld-1.0-SNAPSHOT.jar helloworld.App输出源代码里的程序，显示 HelloWorld! 表示成功。第一个程序1vi HelloWorld.java编译源代码，在当前目录生成HelloWorld.class,然后执行java HelloWorld12javac HelloWorld.javajava HelloWorld重要转换ppk成linux下面支持的密钥文件1sudo pacman -S putty安装putty以后，可以使用如下命令：12puttygen git_cesi.ppk -o id_rsa.pub -O public-opensshputtygen git_cesi.ppk -o id_rsa -O private-openssh参考]]></content>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 终端下发送消息命令]]></title>
    <url>%2Flinux-zhong-duan-xia-fa-song-xiao-xi-ming-ling%2F</url>
    <content type="text"><![CDATA[这里分享一个Linux服务器终端下发送消息的命令。由于平时工作中，必免不了与运维同事之间的信息交换，想到我们都是链的同一台服务器，这样就可以通过以下两个命令来发送消息。给指定用户发送消息首先，可使用w或who命令查看当前登录的用户信息；然后，使用write命令将信息发送到用户的终端上，用法步骤如下：123456789$ w 17:17:53 up 19 days, 57 min, 3 users, load average: 0.00, 0.01, 0.05USER TTY LOGIN@ IDLE JCPU PCPU WHATzq pts/0 14:19 1:50 0.08s 0.02s -bashhcaijin pts/1 10:30 55.00s 7:05 0.23s -bashhcaijin pts/2 17:17 1.00s 0.01s 0.00s w$ write hcaijin pts/1Test send message.然后使用hcaijin账号登录，且tty号为pts/1的登录用户终端会收到如下消息：12Message from hcaijin@hcj-arch on pts/2 at 17:18 ...Test send message.给当前所有用户发送消息给当前登录所有用户发送消息（需要root权限），使用wall（write all的缩写）1$ wall &apos;Test send message to all user.&apos;执行wall命令，所有登录到该机器的控制台(console)界面上都会收到如上所示的消息。引用]]></content>
      <tags>
        <tag>linux</tag>
        <tag>write</tag>
        <tag>wall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下终端里好玩与危险命令汇总]]></title>
    <url>%2Flinux-xia-hao-wan-de-ming-ling%2F</url>
    <content type="text"><![CDATA[最近发现Linux 终端里有很多好玩的命令，这里记录一下，以免下次还得搜索 - -一些好玩的命令sl1$ sltelnet1$ telnet towel.blinkenlights.nlrev1$ revfactor1$ factorcowsay1$ cowsay / cowthinkfortune1$ fortune / fortune-zhcmatrix1$ cmatrixyes12$ yes$ yes I love Chinayes 是一个非常有趣又有用的命令，尤其对于脚本编写和系统管理员来说，它可以自动地生成预先定义的响应或者将其传到终端。toilet12$ toilet hcaijin.com$ toilet -f mono12 -F metal hcaijin.comwhile1$ while true; do echo &quot;$(date &apos;+%D %T&apos; | toilet -f term -F border --gay)&quot;; sleep 1; doneespeak1$ espeak &quot;Tecmint is a very good website dedicated to Foss Community&quot;将你的多媒体音箱的音量调到最大，然后在将这个命令复制到你的终端，来看看你听到上帝的声音时的反应吧。for1for i in &#123;1..19&#125;; do for j in $(seq 1 $i); do echo -ne $i x $j=$((i*j))\\t;done; echo;donebanner1$ banner hcaijin.com终端下有很多危险的命令，千万小心执行。fork炸弹这个命令其实是一个fork炸弹，它会以指数级的自乘，直到所有的系统资源都被利用了或者系统挂起1$ :()&#123; :|:&amp; &#125;:rm删除命令，一定要小心不可用root用户执行以下1$ rm -rf /dd很有用的命令，但是要注意不要运行以下命令，其实我也没有运行过- -1$ dd if=/dev/zero of=/dev/memshred覆盖文件让它不能再读，传说中的文件粉碎机1$ shred --help]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arch Linux 降级安装软件包与禁止自动升级指定软件包]]></title>
    <url>%2Farch-linuxjiang-ji-an-zhuang-ruan-jian-bao-yu-jin-zhi-sheng-ji-bu-xiang-sheng-ji-de-bao-de-fang-fa%2F</url>
    <content type="text"><![CDATA[由于 Arch Linux 采用滚动更新，最近php7.0也开始更新升级了，但是这会导致目前项目还是采用的mysql模块的程序来说真真是不适合升级的。所以，这里在网上查了一下降级安装的方法分享这里。通过备份软件包降级安装找到相应的php备份包，如果你最近没有执行 pacman -Scc以清空包缓存的话，应该在那儿)1ls -l /var/cache/pacman/pkg | grep php如果在，你可以执行pacman -U ×××.pkg.tar.gz来安装旧版本。如果pacman提示文件冲突的话，你可以通过加上-f参数以强制执行，即1pacman -U --force ×××.pkg.tar.gz这个过程会移除现有的包，仔细的计算所有依赖的改变，然后安装你选择的旧版本的软件包以及合适的依赖。通过downgrade程序来自动化降级安装软件包在 AUR 中有一个包叫做downgradeAUR。它是一个简单的 Bash 脚本，它会从你的缓存中寻找旧版本的包，如果没有的话它会搜索 A.R.M.。你可以选择一个旧包来安装。它基本上自动化了上面所述的过程。查看 downgrade –help 获取使用方法的信息。123sudo yaourt -S downgradedowngrade -s php ##搜索相关包版本downgrade php ##降级安装包如何恢复所有包到指定日期如果想恢复所有包到指定日期（比如2014年3月30日），你必须如下例所示编辑 /etc/pacman.conf，从而让 pacman 保持在这个时间点并且直接使用指定的服务器：1234567891011[core]SigLevel = PackageRequiredServer=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch[extra]SigLevel = PackageRequiredServer=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch[community]SigLevel = PackageRequiredServer=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch或者如下例编辑 /etc/pacman.d/mirrorlist：12345## ## Arch Linux repository mirrorlist ## Generated on 2042-01-01 ##Server=http://ala.seblu.net/repos/2014/03/30/$repo/os/$arch然后同步包数据库以强制降级：1# pacman -Syyuu禁止指定包自动升级的方法==注意: 如果你改变了操作系统的一个基本的组件包，你也许需要降级许多包。这些软件包可能在过程中被删除，需要手动一点一点的安装回来；同时，后续升级时要小心，不要重新安装不想要的软件包版本。==1sudo vim /etc/rc.conf添加行IgnorePkg = php php-cgi php-gd这样子,我们就可以禁止上面的三个包自动升级了.如果有其它的包想禁止,直接添加就可以了,记住分隔符要用空格哦.参考文档1)参考文档2)引用]]></content>
      <tags>
        <tag>linux</tag>
        <tag>archlinux</tag>
        <tag>pacman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 服务器上相关脚本日志]]></title>
    <url>%2Flinux-fu-wu-qi-shang-xiang-guan-jiao-ben-ri-zhi%2F</url>
    <content type="text"><![CDATA[用如下命令查询出来结果中包含“ip地址=数量”的攻击者信息：1cat /var/log/secure|awk &apos;/Failed/&#123;print $(NF-3)&#125;&apos;|sort|uniq -c|awk &apos;&#123;print $2&quot;=&quot;$1;&#125;&apos;查看IP所在地：12curl ipinfo.io/&#123;IP&#125;curl cip.cc/&#123;IP&#125;随机生成密码：123function randpw32()&#123; &lt; /dev/urandom tr -dc &apos;!@#$%^&amp;*&apos;_A-Z-a-z-0-9 | head -c$&#123;1:-32&#125;;echo; &#125;function randpw16()&#123; &lt; /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c$&#123;1:-16&#125;;echo; &#125;Chromium 开启代理：123456789function secure_chromium &#123; port=1080 #使用以下两种配置都可以 #export SOCKS_SERVER=localhost:$port #export SOCKS_VERSION=5 #chromium &amp; chromium --proxy-server=&quot;socks://localhost:$port&quot; &amp; exit&#125;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ghost博客手工修改管理员密码方法]]></title>
    <url>%2Fghostbo-ke-shougong-xiu-gai-mi-ma%2F</url>
    <content type="text"><![CDATA[今天修改Ghost密码，因为是粘贴复制，估计是粘贴到了其他字符，导致密码错误登陆后台失败。而且还因为登录尝试次数过多，造成用户被锁定，只能通过发送邮件找回密码，但是，我配置的Gmail邮箱被google限制使用收发邮件功能了应该，以后看一下具体的原因。查找sqlite数据库用户信息Ghost用的sqlite数据库，登陆到服务器，找到sqlite数据库，存放位置默认是在 Ghost 安装目录下的 content/data/ ，名称为ghost.db使用如下命令：123456$ cd /data/www/ghost/content/data/$ sudo sqlite3 ghost.dbsqlite&gt; .help ### 这里已经进到sqlite命令行模式下了，用&quot;.help&quot;查看帮助sqlite&gt; .tables ### 列表所有的表sqlite&gt; .schema ### 列表所有表的结构 这里我们主要看users表 sqlite&gt; selete * from users;到这里就可以列出后台登陆的会员信息了，仔细看一下发现有个status字段的值应该是locked; password字段值是一串使用 BCrypt Hash Generator 生成的密钥。修改密码为新生成的密钥// 更新密码 这里的密码为 admin123sqlite&gt; update users set password = &quot;$2a$10$ahse9xU.Tr9MttVX4tO1zOER7odgDrQuJzgjZI4fm56x84c/2dGqq&quot; where id = 1; ### 更新密码sqlite&gt; update users set status = &quot;active&quot; where id = 1; ### 解锁用户sqlite&gt; .quit完成以上两步，就可以重新登录了。]]></content>
      <tags>
        <tag>ghost</tag>
        <tag>sqlite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派安装Gentoo Linux]]></title>
    <url>%2Fshu-mei-pai-an-zhuang-gentoo-linux%2F</url>
    <content type="text"><![CDATA[Gentoo介绍Gentoo的历史Gentoo Linux （原来被称为 Enoch Linux ) 是在1999年由Daniel Robbins 和一些开发人员开发的。目标就是创建一个没有预编译的二进制文件的Linux发行版并根据所在的硬件平台进行调整。中间因为Gentoo 缺少关键项目，没有自己的包管理系统，后面Robbins 受到FreeBSD包管理系统的启发，开发出了自己的包管理系统，被称为是portage。 Gentoo没有二进制组件，它的包树中只包含源代码，这使它成为可以移植到其他架构上的理想的操作系统。当然，它的不足之处就是需要漫长的安装时间和大量的人工参与。不过，这不就是我们学习Linux的目的嘛。 Gentoo与其他发行版的异同Gentoo安装和大多数流行的Linux发行版很多不同的地方。虽然有自启动光盘，但是没有安装程序。安装Gentoo时，所有事情都是通过命令行手动操作的。没有配置向导也没有GUI工具。不过，它有一个非常有用的安装指南（安装使用手册）。 与其他发行版相比，Gentoo的另外一个不同点在于它没有发行版本。Gentoo是一个元发行版。元发行版指的是它会一直更新下去。使用元发行版的好处在于你可以随时更新到最新的版本程序。缺点就是你将得到非常复杂的包版本，这个版本没有经过彻底的测试，这点与Arch（另一个Linux的发行版本）是一样的。 Gentoo的处理包的方式是一大不同点。大多数发行版使用二进制包的形式来发布包。Gentoo中发布软件包的系统被称为portage。Gentoo的开发人员是受到FreeBSD的ports collection的启发，在port collection 中只有源代码和包含构建源代码的方法的小文件会发布给终端用户。这被称为源代码发布。Gentoo的portage系统是由一组文件组成的，这个文件被称为ebuild，必要的补丁文件是由Gentoo社区创建。Ebuild文件是由一个被称为emerge的工具来读取。 这个文件仅仅运行标准的./configure、make和make install 工具。这意味着你想要运行在Gentoo系统中的每一个应用程序都需要从源代码进行编译。Gentoo的一切都是从源代码进行编译的，因此，这个发行版要负责GCC工具链中的代码修复工作，包括那些改进GCC的性能优化。源代码的发布除了给Linux社区整体带来益处，也为终端用户带来了巨大的好处。当你在Gentoo中安装一个包是，你将可以通过选项来指定哪些模块被安装，哪些不需要安装，这个用来标记的方法就是use。use标记在构建的配置阶段使用，它们可以设置你想要编译应用程序的哪些部分，这样可以为你提供一个快速简洁的轻量级系统。不过，当你发现一些应用程序需要依赖你前面剔出的功能时，那么你就得需要花费更多的时间重新编译程序才能使用这些功能。- - 分区我们是在树莓派上安装Gentoo，所以这里准备一个全新的SD卡，至少要有4GB。拿到SD卡以后，首先我们为SD卡创建分区。==这里，要提醒一下，读卡器上有一个开关可以控制SD卡的读写性。如果，开关按了也没用，把卡拿出来，插拔多几次，主要是有的读卡器接触点不好，我就是遇到这个问题，卡了很长时间。==引导分区，fat32格式根分区，EXT4格式或者其他的Linux文件系统格式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110$ fdisk -lDisk /dev/sda：298.1 GiB，320072933376 字节，625142448 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x86258625设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sda1 * 63 62926604 62926542 30G 7 HPFS/NTFS/exFAT/dev/sda2 62926605 625137344 562210740 268.1G f W95 扩展 (LBA)/dev/sda5 272658432 272863231 204800 100M 83 Linux/dev/sda6 272865280 281253887 8388608 4G 83 Linux/dev/sda7 281255936 616800255 335544320 160G 83 Linux/dev/sda8 616802304 620996607 4194304 2G 83 Linux/dev/sda9 62928896 188758015 125829120 60G 7 HPFS/NTFS/exFAT/dev/sda10 188760064 209731583 20971520 10G 83 Linux分区表记录没有按磁盘顺序。Disk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x00000000设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 31116287 31114240 14.9G c W95 FAT32 (LBA)$ fdisk /dev/sdb欢迎使用 fdisk (util-linux 2.27)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：pDisk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x00000000设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 31116287 31114240 14.9G c W95 FAT32 (LBA)命令(输入 m 获取帮助)：d已选择分区 1分区 1 已删除。命令(输入 m 获取帮助)：命令(输入 m 获取帮助)：n分区类型 p 主分区 (0个主分区，0个扩展分区，4空闲) e 扩展分区 (逻辑分区容器)选择 (默认 p)：p分区号 (1-4，默认 1)：第一个扇区 (2048-31116287，默认 2048)：上个扇区，+sectors 或 +size&#123;K,M,G,T,P&#125; (2048-31116287，默认 31116287)：+100M创建了一个新分区 1，类型为“Linux”，大小为 100 MiB。命令(输入 m 获取帮助)：n分区类型 p 主分区 (1个主分区，0个扩展分区，3空闲) e 扩展分区 (逻辑分区容器)选择 (默认 p)：p分区号 (2-4，默认 2)：第一个扇区 (206848-31116287，默认 206848)：上个扇区，+sectors 或 +size&#123;K,M,G,T,P&#125; (206848-31116287，默认 31116287)：创建了一个新分区 2，类型为“Linux”，大小为 14.8 GiB。命令(输入 m 获取帮助)：pDisk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x00000000设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 206847 204800 100M 83 Linux/dev/sdb2 206848 31116287 30909440 14.8G 83 Linux命令(输入 m 获取帮助)：t分区号 (1,2，默认 2)：1分区类型(输入 L 列出所有类型)：c已将分区“Linux”的类型更改为“W95 FAT32 (LBA)”。命令(输入 m 获取帮助)：pDisk /dev/sdb：14.9 GiB，15931539456 字节，31116288 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x00000000设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 206847 204800 100M c W95 FAT32 (LBA)/dev/sdb2 206848 31116287 30909440 14.8G 83 Linux命令(输入 m 获取帮助)：w分区表已调整。将调用 ioctl() 来重新读分区表。正在同步磁盘。接下来，将分区按照它们自己的文件系统格式进行格式化。12345678910111213141516171819202122232425$ mkfs /dev/sdb1mke2fs 1.42.12 (29-Aug-2014)/dev/sdb1 contains a ext2 file system last mounted on /mnt/cdrom/armv7 on Thu Sep 24 19:40:44 2015无论如何也要继续? (y,n) yCreating filesystem with 102400 1k blocks and 25688 inodesFilesystem UUID: 256e4119-5d49-4303-9ca2-a28638838ce6Superblock backups stored on blocks: 8193, 24577, 40961, 57345, 73729Allocating group tables: 完成 正在写入inode表: 完成 Writing superblocks and filesystem accounting information: 完成 $ mkfs.ext4 /dev/sdb2mke2fs 1.42.12 (29-Aug-2014)Creating filesystem with 3863680 4k blocks and 966656 inodesFilesystem UUID: a0a95364-389a-4c4d-b63e-e1e61ed4b6c3Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208Allocating group tables: 完成 正在写入inode表: 完成 Creating journal (32768 blocks): 完成Writing superblocks and filesystem accounting information: 完成现在，我们已经创建好了两个可以使用的文件系统。然后，我们把相应分区挂载到/mnt 目录下。123$ mkdir -p /mnt/raspberry/ $ mount /dev/sdb2 /mnt/raspberry #### 首先挂载根分区$ mkdir -p /mnt/raspberry/boot &amp;&amp; mount /dev/sdb1 /mnt/raspberry/boot ### 再挂载引导分区到根分区目录里的boot下。这个引导分区和其他的树莓派引导分区类似。它包含基金会提供的固件、命令行参数、配置文件和内核。创建引导文件系统的第一步是从基金会的GitHub网站上获取固件文件：https://github.com/raspberrypi/firmware/tree/master/boot1234$ cd /mnt/raspberry/boot$ wget https://github.com/raspberrypi/firmware/tree/master/boot/bootcode.bin$ wget https://github.com/raspberrypi/firmware/tree/master/boot/start.elf$ wget https://github.com/raspberrypi/firmware/tree/master/boot/fixup.dat分别下载这三个文件就可以了。接下来，需要创建cmdline.txt 和 config.txt 两个文件。内容如下：1234567891011121314$ cat cmdline.txtroot=/dev/mmcblk0p2 rootdelay=2$ cat config.txtgpu_mem=32######完成以上步骤，用ls -l 看一下引导分区现在的文件。$ ls -l总用量 104-rw-r--r-- 1 root root 29026 9月 24 22:54 bootcode.bin-rw-r--r-- 1 root root 32 9月 24 22:59 cmdline.txt-rw-r--r-- 1 root root 11 9月 24 23:00 config.txt-rw-r--r-- 1 root root 29219 9月 24 22:56 fixup.datdrwx------ 2 root root 12288 9月 24 22:33 lost+found-rw-r--r-- 1 root root 29221 9月 24 22:56 start.elf安装下载系统包http://distfiles.gentoo.org/releases/arm/autobuilds/current-stage3-armv7a_hardfp/12345678910111213141516171819202122232425$ cd ~/Downloads/$ wget http://distfiles.gentoo.org/releases/arm/autobuilds/current-stage3-armv7a_hardfp/stage3-armv7a_hardfp-20150730.tar.bz2$ tar xfj ~/Downloads/stage3-armv7a_hardfp-20150730.tar.bz2 -C /mnt/raspberry ### -C 指定解压的目录。解压需要一些时间，完成以后，看上去如下：$ ls -al总用量 89drwxr-xr-x 20 root root 4096 7月 30 13:50 .drwxr-xr-x 4 root root 4096 9月 24 22:38 ..drwxr-xr-x 2 root root 4096 7月 30 21:22 bindrwxr-xr-x 3 root root 1024 7月 30 13:50 bootdrwxr-xr-x 3 root root 4096 7月 30 13:50 devdrwxr-xr-x 31 root root 4096 7月 30 21:31 etcdrwxr-xr-x 2 root root 4096 7月 30 13:50 homedrwxr-xr-x 10 root root 4096 7月 30 21:27 libdrwx------ 2 root root 16384 9月 24 22:33 lost+founddrwxr-xr-x 2 root root 4096 7月 30 13:50 mediadrwxr-xr-x 2 root root 4096 7月 30 13:50 mntdrwxr-xr-x 2 root root 4096 7月 30 13:50 optdrwxr-xr-x 2 root root 4096 7月 30 13:18 procdrwx------ 2 root root 4096 7月 30 13:50 rootdrwxr-xr-x 3 root root 4096 7月 30 21:22 rundrwxr-xr-x 2 root root 4096 7月 30 21:31 sbindrwxr-xr-x 2 root root 4096 7月 30 13:50 sysdrwxrwxrwt 2 root root 4096 7月 30 21:31 tmpdrwxr-xr-x 11 root root 4096 7月 30 21:31 usrdrwxr-xr-x 9 root root 4096 7月 30 13:50 var到这里，相信大家都很熟悉这个目录了。配置系统文件第一步就是配置fstab，因为这是系统引导完成以后最先需要挂载好文件系统。==这里千万要注意修改的是 /mnt/raspberry/etc/fstab ==12345$ cat etc/fstab # &lt;fs&gt; &lt;mountpoint&gt; &lt;type&gt; &lt;opts&gt; &lt;dump/pass&gt;# NOTE: If your BOOT partition is ReiserFS, add the notail option to opts./dev/mmcblk0p1 /boot ext2 noauto,noatime 1 2/dev/mmcblk0p2 / ext4 noatime 0 1不要使用/dev/sdX设置的引用 。因为SD卡在树莓派上被视为/dev/mmcdlk0 。因为无法chroot到新的构建环境中，所以需要手动设置一些东西。首先，为Gentoo系统设置一个新的root用户密码。如下，1234$ openssl passwd -1Password: Verifying - Password: $1$ZoQIFaY4$3Re0RSS0qu6nds3wvqlRf1以上，最后一行就是我们的encrypted密码，把它放到/etc/shadow文件中。12$ cat etc/shadow | grep rootroot:$1$ZoQIFaY4$3Re0RSS0qu6nds3wvqlRf1:10770:0:::::配置 portage到目前为止，已经完成了所有的系统配置。但是，这还不是最终的系统，现在我们必须解压当前的portage集合。这样，才能在系统引导时，构建应用程序。下载，我们到以下地址去下载portage包。http://distfiles.gentoo.org/releases/snapshots/current/portage-lastest.tar.bz2123$ cd ~/Downloads/$ wget http://distfiles.gentoo.org/releases/snapshots/current/portage-latest.tar.bz2$ tar xjvpf ~/Downloads/portage-latest.tar.bz2 -C /mnt/raspberry/usr交叉编译环境构造一个最小的 Linux 系统，==主要分为两步：第一步是构建一个宿主系统无关的新工具链（编译器、汇编器、链接器、库和一些有用的工具）。第二步则是使用该工具链构建其它的基础工具。==这里说的工具链就是说的交叉编译环境。下载系统内核到了这一步以后，我们需要为新的Gentoo系统构建一个内核。为了完成这一步，需要有相关配置交叉编译环境基础知识。还需要内核源码,这里我们使用树莓派官方内核源码，因为这将包含所有已经打好的树莓派的补丁。到GitHub上clone一份内核源码或者下载zip包，如下：12$ git clone https://github.com/raspberrypi/linux$ cd linux为什么要使用交叉编译环境交叉编译是在你的宿主系统上编译不同机器类型的应用程序。因为，树莓派使用的ARM架构与宿主机系统x86机器类型不同，只有使用相同的CPU机器类型才能使用chroot引导新系统。所以，这里就得用到交叉编译环境，在宿主系统上编译出ARM架构的树莓派。 在开始之前，希望大家可以先看一下《Linux 从零开始》 。crosstool-NG暂时写到这里，以后再补充。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>Gentoo</tag>
        <tag>Raspberry Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置博客ghost使用https 及安装StartSSL免费SSL证书]]></title>
    <url>%2Fnginxpei-zhi-https-ji-an-zhuang-startsslmian-fei-sslzheng-shu%2F</url>
    <content type="text"><![CDATA[今天配置安装ssl证书碰到了不少的问题，这里记录一下。HTTP协议默认情况下是不加密的，各种密码，邮件的传输都是明文的，极有可能被互联网上的黑客给获取，造成隐私泄漏。SSL是Secure Socket Layer的简称，具体的作用就是在部署了SSL证书的网站跟用户浏览器之间建立一个安全的会话。nginx编译安装ssl模块在说安装证书之前，我先说一下，nginx 要想使用ssl需要在编译安装的时候加上配置参数 --with-zlib=/data/nginx/lib/ 使用命令先看一下nginx配置123456$ /usr/local/nginx/sbin/nginx -Vnginx version: nginx/1.9.0built by gcc 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) built with OpenSSL 1.0.1e-fips 11 Feb 2013TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module如果在configure arguments: 没有找到ssl相关模块，就得重新编译一下。找到nginx源码包，执行以下命令，如下：==这里提醒一下，安装软件的时候我觉得还是在root权限下方便，而且可以避免不必要的无权限执行报错，即使有sudo的权限。==123456$ cd nginx-1.9.0$ ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module ##这里的stub模块是个统计性能用的，与本文无关，你也可以不安装这个。$ make ##这里不要使用 make install，否则就覆盖安装了 make完之后在objs目录下就多了个nginx，这个就是新版本的程序了$ cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak$ cp objs/nginx /usr/local/nginx/sbin/nginx$ /usr/local/nginx/sbin/nginx -V ##这里就可以使用新版本的程序看一下编译参数里已经有ssl模块了。证书安装这里说一下，免费的SSL与付费的SSL还是有区别的，我主要是为博客后台登陆使用SSL，学习配置一下。StartCom公司是到目前止仅有的还提供免费SSL服务的公司（应该是吧，我也是听别人说的），支持多种浏览器的正常识别，只要通过他们的个人信息审核就可以免费使用一年的时间。我自己审核的时候，本想随便写个英文名称，地址，但是都被弊掉了。建议填写个人信息的时候还是要尽量真实。这样才能够一次性通过邮件审核。StartSSL官方首页 具体申请流程我就不说了，打开官方网站看一下就知道了。我们来说一下，安装的流程：首先使用ssh登陆vps，执行如下命令生成证书1$ openssl req -new -newkey rsa:2048 -nodes -out server.csr -keyout server.key以上生成的server.csr 需要把内容粘贴到 StartSSL 去生成域名证书了。这里生成的server.key 是没有passphrase的，所以这一节我们可以跳过不看。如果有配置密码的话，我们需要去掉private key的passphrase才能让Nginx自由自在的启动。12$ cp server.key server.key.bak$ sudo openssl rsa -in server.key.bak -out server.key开始配置nginx123456789101112131415161718192021server &#123; listen 443 ssl; server_name hcaijin.com www.hcaijin.com; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; &#125; ssl_certificate /usr/local/nginx/ssl/hcjwebssl.crt; ssl_certificate_key /usr/local/nginx/ssl/hcjnopassssl.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on;&#125;配置把http的请求转到https1234567891011121314151617server &#123; listen 80; server_name hcaijin.com www.hcaijin.com; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; &#125; #rewrite ^(.*) https://$server_name$1 permanent; location ~ /ghost(/.*) &#123; rewrite ^ https://$server_name$request_uri? permanent; &#125;&#125;1$ /etc/init.d/nginx restart ##重启一下nginx服务解决Firefox浏览器不信任StartSSL免费SSL的问题1234$ wget http://cert.startssl.com/certs/ca.pem $ wget http://cert.startssl.com/certs/sub.class1.server.ca.pem $ sudo cat ca.pem sub.class1.server.ca.pem &gt;&gt; server.crt$ /etc/init.d/nginx restart]]></content>
      <tags>
        <tag>ghost</tag>
        <tag>openssl</tag>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arch Linux 配置Bluetooth]]></title>
    <url>%2Farch-linux-pei-zhi-bluetooth%2F</url>
    <content type="text"><![CDATA[蓝牙是一个短距离无线通信标准，适用于手机、计算机和其他电子设备之间的通信。在 Linux 中，通常使用的蓝牙协议栈实现是 BlueZ.安装为了使用蓝牙(Blutooth)，必须要安装官方仓库中的 bluez 软件包。$ sudo pacman -S bluez bluez-utils bluez会使用dbus 服务读取设置和进行pin(个人识别码 personal identification number)配对。蓝牙(Bluetooth)协议需要bluetooth服务来支撑：$ sudo systemctl enable bluetooth.service $ sudo systemctl start bluetooth.service 加载通用蓝牙驱动程序，如果还没有装载：$ modprobe btusb 配置bluetoothctl使用bluetoothctl 需要安装bluez-utils 包。这个在上一步里已经执行过了，这里就直接说配置与使用的方法：$ bluetoothctl help 列出帮助文档。首先执行 power on 打开蓝牙适配器的电源开关，这样蓝牙的LED灯会亮起(默认是关闭的)。先用命令 devices 列出有已匹配的设备MAC地址如果列表为空，那么就要使用 scan on 来扫描网络中开启蓝牙的设备开启代理 agent on输入命令 pair [MAC Address] 匹配两个蓝牙设备如果使用设备没有PIN，要成功地重新连接设备之前，可能需要手动信任设备。输入 trust [MAC Address]如果以上步骤都没有问题的话，那么就可以链接你的蓝牙设备了。 connect [MAC Address]Obex使用obexctl是在蓝牙设备之间发送和接收文件的工具，是随bluez包安装好了的,在终端直接输入 obexctl 就可以进入obex环境，如图：另外还有一个命令行工具obexfs (包括obexfs,obexftp等)$ sudo pacman -S obexfs 安装好了就可以使用命令直接挂载蓝牙设备到本地目录，$ obexfs -b MAC_address_of_device -p /mnt/bluez/ 一旦你完成了，卸载的设备使用以下命令：$ fusermount -u /mnt/bluez/ 如果您的设备支持FTP服务，但你不希望加载该设备，您可以使用obexftp传输文件在设备之间。发送文件：$ obexftp -b MAC_address_of_device -p /path/to/file 接收文件：$ obexftp -b MAC_address_of_device -g filename Bluetooth USB 适配器如果你在使用USB适配器，你应当确认你的适配器被正确识别。你可以在插入适配器时通过查看/var/log/messages.log （或者journalctl -f)，$ tail -f /var/log/messages.log 这应当会出现类似于下面所示的信息：May 2 23:36:40 tatooine usb 4-1: new full speed USB device using uhci_hcd and address 9May 2 23:36:40 tatooine usb 4-1: configuration #1 chosen from 1 choiceMay 2 23:36:41 tatooine hcid[8109]: HCI dev 0 registeredMay 2 23:36:41 tatooine hcid[8109]: HCI dev 0 upMay 2 23:36:41 tatooine hcid[8109]: Device hci0 has been addedMay 2 23:36:41 tatooine hcid[8109]: Starting security manager 0May 2 23:36:41 tatooine hcid[8109]: Device hci0 has been activated如果你只得到了前面两行，说明了电脑发现了这个设备，但是你需要手动启动它。 例如：$ hciconfig -a hci0 $ hciconfig hci0 up 如果不能从你的手机发现电脑，那么就需要启用PSCAN和ISCAN：$ hciconfig hci0 piscan 注意: 检查/etc/bluetooth/main.conf中的发现倒计时和配对倒计时试着在 /etc/bluetooth/main.conf 改变设备的class修改：Class = 0x100100==参考：https://wiki.archlinux.org/index.php/Bluetooth ==]]></content>
      <tags>
        <tag>archlinux</tag>
        <tag>bluetooth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[导出CSV文件，对长数字字符会自动显示科学计数解决方法]]></title>
    <url>%2Fphpdao-chu-csvwen-jian-dui-chang-shu-zi-zi-fu-hui-zi-dong-xian-shi-ke-xue-ji-shu-jie-jue-fang-fa%2F</url>
    <content type="text"><![CDATA[今天做csv导出遇到订单号太长导致导出来用EXCEL打开显示为科学计数了，最后几位直接显示为0。但是用文本方式打开订单号是正常的，这说明一定是与EXcel有关系。GOOGLE了一下，找到EXCEL相关介绍：Excel显示数字时，如果数字大于12位，它会自动转化为科学计数法；如果数字大于15位，它不仅用于科学技术费表示，还会只保留高15位，其他位都变0。$oid = &quot;\t&quot;.$val[&apos;oid&apos;]; 如果是phpexcel导出的话，把”\t”换成” “即可。]]></content>
      <tags>
        <tag>csv</tag>
        <tag>excel</tag>
        <tag>phpexcel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 无线网卡状态异常修复]]></title>
    <url>%2Fjie-jue-linux-wu-xian-wang-qia-zhuang-tai-yi-chang%2F</url>
    <content type="text"><![CDATA[无线网卡异常，有很多种原因造成。这里我是因为有做AP共享WIFI，本来好好的，不知道怎么实然，我手机wifi断了，再看，从PC共享的WIFI竟然挂了。就这样，下班回家，准备链接无线路由，因为有换新的网，得重新链接：$ sudo wifi-menu -o 竟然报No networks found重启了问题依然存在，没办法，只能用有线先连着。开始Google：No networks found我一开始就找错了方向，自然是没有找到解决的方法。经过这次，让我对日志的记录有了更深的认识，以前，觉得日志记录太难看得懂了，从来都是很少去看，浪费了很多时间在无用的地方，这里给自己个警戒，凡是就得先看日志信息。这样，接下来，在日志里有发现有这个错误 Operation not possible due to RF-killGoogle一下，就找到了问题的关键，原因RF-KILL其实是一个打开和关闭无线设备的工具。 由此可以知道，这是一打开无线设备wifi的错误。因为我用的arch没有安装rfkill,执行：$ sudo pacman -S rfkill 安装好以后，为了查看当前的无限网卡的状态，执行命令rfkill list all ——列出所有无线设备的当前状态。结果如下：发现 Hard blocked 和 soft blocked 之间的同步失败,具体原因可以看这里“SIOCSIFFLAGS: Operation not possible due to RF-kill”?找到问题原因，我们可以使用命令使软硬设备同步:$ rfkill unblock wifi 用命令 rfkill list all 列出所有无线设备状态看一下结果，好了，无线网卡状态异常的问题修复了。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>wifi</tag>
        <tag>RF-kill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PPTP 服务器端安装与配置详解]]></title>
    <url>%2Fpptp-fu-wu-qi-duan-an-zhuang-yu-pei-zhi-xiang-jie%2F</url>
    <content type="text"><![CDATA[安装前环境检查因为pptp需要MPPE的支持，所以首先检测系统是否符已经编译了MPPE。下面介绍两种检测方法，只要符合其中的一条就可以第一种：# zgrep MPPE /proc/config.gz CONFIG_PPP_MPPE=y # cat /dev/net/tun cat: /dev/net/tun: File descriptor in bad state 第二种：网上大多数资料还提到了另一个测试命令$ modprobe ppp-compress-18 &amp;&amp; echo ok FATAL: Module ppp_mppe not found. 如果返回“OK”说明可以安装PPTP，我查了一下，这个命令是在CentOS 4.4版本中有人提出的，但是经过实际测试，发现在我的环境中非但没有效果，而且报错。所以如果modprobe ppp-compress-18 &amp;&amp; echo ok没有显示“OK”甚至报错，并不代表不能安装。最好还是用上面那种方法查看。安装依赖由于pptp需要iptables支持，所以需要安装iptables。如果您的服务器上已经安装了iptables，那么可以只安装pptp$ yum install -y ppp iptables 注意：这里先安装的是ppp而不是pptp，不要打错了。另：PPP是一种数据链路层协议类似我们熟知的pppoe接下来就是一大堆的信息，无非是寻找最快的源，找到后下载相关安装包，下载完成自动安装。如果回到提示符状态，并且安装结果为Complete!，说明安装成功。安装pptp现在我们可以正式安装VPN Server了。这里我们选择pptp(VPN 协议的一种),因为简单，一条命令搞定。剩下的无非是一些配置。yum -y install pptpd配置pptp编辑/etc/ppp/options.pptpdpptpd安装完成后，编辑/etc/pptpd.conf文件，去掉下面两行的注释或者直接添加这两行(在文件的最后).这一步是配置ip地址的范围。localip 192.168.0.1remoteip 192.168.0.100-150设置使用pptp的用户名和密码然后在/etc/ppp/chap-secrets文件中添加VPN用户，按照下面的格式,每个用户一行。username pptpd password *配置DNS服务器为了让你的用户连上VPN后能够正常地解析域名，我们需要手动设置DNS. 编辑/etc/ppp/options，找到ms-dns这一项，设置你的DNS.这里我推荐的是Google 最近发布的Public DNS,原因是因为好记。ms-dns 8.8.8.8ms-dns 209.244.0.3ms-dns 208.67.222.222ms-dns 8.8.4.4修改内核设置，使其支持转发。编辑/etc/sysctl.conf文件，找到”net.ipv4.ip_forward=1″这一行，去掉前面的注释并注释掉 “net.ipv4.tcp_syncookies=1”。net.ipv4.ip_forward=1 #net.ipv4.tcp_syncookies = 1 运行下面的命令让配置生效。$ sysctl -p iptables转发$ iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 12.34.56.78 (适合于OpenVZ架构的VPS,12.34.56.78为您VPS的公网IP地址)$ iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE (适合于XEN架构的VPS)以上两条命令分别对应OpenVZ架构和XEN架构的VPS，您的VPS是什么架构需要询问供应商。Linode采用的是XEN架构，所以输入我的是搬瓦工的vps,配置如下：$ iptables -t nat -A POSTROUTING -o venet0 -s 192.168.0.0/24 -j SNAT --to-source `ifconfig | grep &apos;inet addr:&apos;| grep -v &apos;127.0.0.1&apos; | cut -d: -f2 | awk &apos;NR==1 { print $1}&apos;` 运行1/etc/init.d/pptpd start]]></content>
      <tags>
        <tag>pptp</tag>
        <tag>iptables</tag>
        <tag>vps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中的文件特殊权限]]></title>
    <url>%2Flinuxzhong-de-wen-jian-te-shu-quan-xian%2F</url>
    <content type="text"><![CDATA[linux中除了常见的读（r）、写（w）、执行（x）权限以外，还有3个特殊的权限，分别是setuid、setgid和stick bitsetuid、setgid先看个实例，查看你的/usr/bin/passwd 与/etc/passwd文件的权限# ls -l /usr/bin/passwd /etc/passwd -rw-r--r-- 1 root root 1549 08-19 13:54 /etc/passwd -rwsr-xr-x 1 root root 22984 2007-01-07 /usr/bin/passwd 众所周知，/etc/passwd文件存放的各个用户的账号与密码信息，/usr/bin/passwd是执行修改和查看此文件的程序，但从权限上看，/etc/passwd仅有root权限的写（w）权，可实际上每个用户都可以通过/usr/bin/passwd命令去修改这个文件，于是这里就涉及了linux里的特殊权限setuid，正如-rwsr-xr-x中的ssetuid就是：让普通用户拥有可以执行“只有root权限才能执行”的特殊权限，setgid同理指”组“作为普通用户是没有权限修改/etc/passwd文件的，但给/usr/bin/passwd以setuid权限后，普通用户就可以通过执行passwd命令，临时的拥有root权限，去修改/etc/passwd文件了stick bit （粘贴位）再看个实例，查看你的/tmp目录的权限# ls -dl /tmp drwxrwxrwt 6 root root 4096 08-22 11:37 /tmp tmp目录是所有用户共有的临时文件夹，所有用户都拥有读写权限，这就必然出现一个问题，A用户在/tmp里创建了文件a.file，此时B用户看了不爽，在/tmp里把它给删了（因为拥有读写权限），那肯定是不行的。实际上是不会发生这种情况，因为有特殊权限stick bit（粘贴位）权限，正如drwxrwxrwt中的最后一个tstick bit (粘贴位)就是：除非目录的属主和root用户有权限删除它，除此之外其它用户不能删除和修改这个目录。也就是说，在/tmp目录中，只有文件的拥有者和root才能对其进行修改和删除，其他用户则不行，避免了上面所说的问题产生。用途一般是把一个文件夹的的权限都打开，然后来共享文件，象/tmp目录一样。设置方法setuid：chmod u+s xxxsetgid: chmod g+s xxxstick bit : chmod o+t xxx或者使用八进制方式，在原先的数字前加一个数字，三个权限所代表的进制数与一般权限的方式类似，如下:suid guid stick bit 1 1 1 所以：suid的二进制串为：100，换算十进制为：4guid的二进制串为:010,换算：2stick bit 二进制串：001，换算：1于是也可以这样设:setuid:chmod 4755 xxxsetgid:chmod 2755 xxxstick bit:chmod 1755 xxx最后，在一些文件设置了特殊权限后，字母不是小写的s或者t，而是大写的S和T，那代表此文件的特殊权限没有生效，是因为你尚未给它对应用户的x权限]]></content>
      <tags>
        <tag>linux</tag>
        <tag>setuid</tag>
        <tag>setgid</tag>
        <tag>stick bit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php session 丢失BUG修改]]></title>
    <url>%2Fphp-session-diu-shi-bugxiu-gai%2F</url>
    <content type="text"><![CDATA[今天真是被这个问题给郁闷到了，调试了代码半天时间，终于从http://www.111cn.net/phper/php-cy/56742.htm 里找到了线索。就是存储session的目录权限不可写，或者目录空间満了写不进去就会出现这个BUG.$ ls -al / drwxr-xr-x. 12 root root 53248 Jun 15 17:14 tmp 发现/tmp 目录权限不对。后面，打开Thinkphp debug ,trace 页面查找到 open(‘/tmp/sess_ifoeq9834f98h4h54’,O_REIOR) promostion demoin总结一下， 就是遇到问题，日志才是最好的排错地方。这里记录一下，以免以后又犯错，直接去调试代码，花费了不小的功夫，还找不到原因。]]></content>
      <tags>
        <tag>php</tag>
        <tag>session</tag>
        <tag>Thinkphp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX ssh 用户配置文件 config 管理]]></title>
    <url>%2Flinux-ssh-yong-hu-pei-zhi-wen-jian-config-guan-li%2F</url>
    <content type="text"><![CDATA[利用 ssh 的用户配置文件 config 管理 ssh 会话。ssh 的用户配置文件是放在当前用户根目录下的 .ssh 文件夹里（~/.ssh/config，不存在则新创建一个），其配置写法如下：Host test User root HostName 192.168.3.152 PassWord V8kbwqsV0UGTob8EEeL4 Host * #PubkeyAuthentication no IdentityFile ~/.ssh/id_rsa 这样我们就可以使用如下命令直接登陆到hostname 为192.168.3.152 的服务器了：# ssh test 使用密钥的好处就是省去每次 ssh 登陆服务器时都要输入登陆密码的操作，这里使用 ssh-keygen 生成 ssh 密钥与公钥：# ssh-keygen -t rsa 把公钥 id_rsa.pub 上传到远程 192.168.3.152 服务器的 ~/.ssh/ 目录下：# ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.3.152 这样会在服务器的 ~/.ssh/ 目录下生成文件 authorized_keys这里注意一点：以 ssh publickey 的形式访问，对当前用户根目录下的 .ssh 文件夹里的目录文件是要有一定的权限要求，之前遇到过 ssh publickey 配置好了，不过用 publickey 登陆验证时则无效。所以，最好设下.ssh 目录权限为 700，authorized_keys 权限为 600，并检查当前用户目录所属的用户组，如：# ls -al .ssh/ total 12 drwx------ 2 root root 4096 Jun 13 16:20 . drwxr-xr-x. 5 other others 4096 Jun 13 16:15 .. -rw------- 1 root root 401 Jun 13 16:20 authorized_keys 以上，注意目录 .ssh/ 父目录用户所属用户组，用户。这样也会造成使用publickey 登陆验证时无效，还是提示要输入密码。# chown -R root.root /root/ 当然，用密钥的方式连接服务器是需要服务器上的 ssh 支持的，需要 ssh 的配置文件（默认是在 etc/ssh/sshd_config）里的 PubkeyAuthentication 设置成 yes。如果要改登陆的端口，直接把 Port 改成你想要的端口值就行。修改完后重启下 ssh ，配置就生效：# /etc/init.d/sshd restart 然后，就可以使用ssh 别名登陆服务器了。用 ssh 作 socks5 代理翻墙，以后不用这样写了(hcj.com 为在墙外的代理服务器)：# ssh -CfNg -D1080 hcj.com 使用 scp 传送可以简写成这样：# scp ~/.ssh/id_rsa.pub test:~/.ssh/authorized_keys 执行远程 ssh 命令：# ssh test &apos;ls -al ~&apos; 打包一个文件（假设当前目录有个名为 test 的文件夹），接着上传到远程服务器，最后解压文件# tar -zcvf - ./test/ | ssh test &apos;cd /user/; tar xvfz -&apos;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 设置大小写敏感]]></title>
    <url>%2Fmysql-she-zhi-da-xiao-xie-min-gan%2F</url>
    <content type="text"><![CDATA[1、linux下mysql安装完后是默认：区分表名的大小写，不区分列名的大小写；2、如何设置为不区分表名的大小写：修改mysql配置文件/etc/mysql/my.cnf 中,在[mysqld]后添加lower_case_table_names=1，默认为0表示区分大小写，然后重启MYSQL服务。；3、Mysql 在不同的操作系统中大小写敏感区别：3.1、MySQL在Linux下数据库名、表名、列名、别名大小写规则是这样的：数据库名与表名是严格区分大小写的；表的别名是严格区分大小写的；列名与列的别名在所有的情况下均是忽略大小写的；变量名也是严格区分大小写的；3.2、MySQL在Windows下都不区分大小写。4、如果想在查询时区分字段值的大小写，则：字段值需要设置BINARY属性，设置的方法有多种：A、创建时设置：CREATE TABLE T(A VARCHAR(10) BINARY);B、使用alter修改：ALTER TABLE tablename MODIFY COLUMN cloname VARCHAR(45) BINARY;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL导入导出csv文件命令行操作]]></title>
    <url>%2Fmysqldao-ru-dao-chu-csvwen-jian-ming-ling-xing-cao-zuo%2F</url>
    <content type="text"><![CDATA[1、先确认一下cvs的文件格式，确保与表编码一至。设为utf82、创建表，设置为utf83、登陆mysql, 导入csv文件$ mysql -uroot -p MariaDB []&gt; create database test; use test; MariaDB [test]&gt; LOAD DATA INFILE &apos;/mysql/test_data.csv&apos; REPLACE INTO TABLE test_table CHARACTER SET utf8 FIELDS TERMINATED BY &apos;,&apos; ENCLOSED BY &apos;&quot;&apos; LINES TERMINATED BY &apos;\r\n&apos;; 注意：test_data.csv 要在mysql 的用户权限中，即使放到/tmp 目录下也是有问题的，暂时不知道怎么解决。$ sudo mkdir /mysql ; $ sudo chown -R mysql.mysql /mysql $ sudo cp ~/test_data.csv /mysql/]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>csv</tag>
        <tag>utf8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置高并发]]></title>
    <url>%2Fnginx-pei-zhi-gao-bing-fa%2F</url>
    <content type="text"><![CDATA[一般来说nginx 配置文件中对优化比较有作用的为以下几项：worker_processes 8;nginx 进程数，建议按照cpu 数目来指定，一般为它的倍数 (如,2个四核的cpu计为8)。worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;为每个进程分配cpu，上例中将8 个进程分配到8 个cpu，当然可以写多个，或者将一个进程分配到多个cpu。worker_rlimit_nofile 65535;这个指令是指当一个nginx 进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx 进程数相除，但是nginx 分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。查看linux系统文件描述符的方法：[root@web001 ~]# sysctl -a | grep fs.filefs.file-max = 789972fs.file-nr = 510 0 789972use epoll;使用epoll 的I/O 模型(补充说明:与apache相类，nginx针对不同的操作系统，有不同的事件模型A）标准事件模型 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll B）高效事件模型 Kqueue：使用于 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X. 使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。Epoll: 使用于Linux内核2.6版本及以后的系统。/dev/poll：使用于 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。Eventport：使用于 Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 )worker_connections 65535;每个进程允许的最多连接数， 理论上每台nginx 服务器的最大连接数为worker_processes*worker_connections。keepalive_timeout 60;keepalive 超时时间。client_header_buffer_size 4k;客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE 取得。[root@web001 ~]# getconf PAGESIZE4096但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。open_file_cache max=65535 inactive=60s;这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。open_file_cache_valid 80s;这个是指多长时间检查一次缓存的有效信息。open_file_cache_min_uses 1;open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。关于内核参数的优化：net.ipv4.tcp_max_tw_buckets = 6000timewait 的数量，默认是180000。net.ipv4.ip_local_port_range = 1024 65000允许系统打开的端口范围。net.ipv4.tcp_tw_recycle = 1启用timewait 快速回收。net.ipv4.tcp_tw_reuse = 1开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。net.ipv4.tcp_syncookies = 1开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。net.core.somaxconn = 262144web 应用中listen 函数的backlog 默认会给我们内核参数的net.core.somaxconn 限制到128，而nginx 定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。net.core.netdev_max_backlog = 262144每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。net.ipv4.tcp_max_orphans = 262144系统中最多有多少个TCP 套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。net.ipv4.tcp_max_syn_backlog = 262144记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。net.ipv4.tcp_timestamps = 0时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。net.ipv4.tcp_synack_retries = 1为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。net.ipv4.tcp_syn_retries = 1在内核放弃建立连接之前发送SYN 包的数量。net.ipv4.tcp_fin_timeout = 1如 果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。net.ipv4.tcp_keepalive_time = 30当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。下面贴一个完整的内核优化设置:vi /etc/sysctl.conf CentOS5.5中可以将所有内容清空直接替换为如下内容:net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 262144net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65000使配置立即生效可使用如下命令：/sbin/sysctl -p下面是关于系统连接数的优化linux 默认值 open files 和 max user processes 为 10241ulimit -n10241ulimit –u1024问题描述： 说明 server 只允许同时打开 1024 个文件，处理 1024 个用户进程使用ulimit -a 可以查看当前系统的所有限制值，使用ulimit -n 可以查看当前的最大打开文件数。新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files 。因此，需要将其改大。解决方法：使用 ulimit –n 65535 可即时修改，但重启后就无效了。（注ulimit -SHn 65535 等效 ulimit -n 65535 ，-S 指soft ，-H 指hard)有如下三种修改方式：在/etc/rc.local 中增加一行 ulimit -SHn 65535在/etc/profile 中增加一行 ulimit -SHn 65535在/etc/security/limits.conf 最后增加：soft nofile 65535hard nofile 65535soft nproc 65535hard nproc 65535具体使用哪种，在 CentOS 中使用第1 种方式无效果，使用第3 种方式有效果，而在Debian 中使用第2 种有效果1ulimit -n655351ulimit -u65535备注：ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制soft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。 soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值。下面是一个简单的nginx 配置文件：user www www;worker_processes 8;worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 0010000001000000;error_log /www/log/nginx_error.log crit;pid /usr/local/nginx/nginx.pid;worker_rlimit_nofile 204800;events{use epoll;worker_connections 204800;}http{include mime.types;default_type application/octet-stream;charset utf-8;server_names_hash_bucket_size 128;client_header_buffer_size 2k;large_client_header_buffers 4 4k;client_max_body_size 8m;sendfile on;tcp_nopush on;keepalive_timeout 60;fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2keys_zone=TEST:10minactive=5m;fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 4k;fastcgi_buffers 8 4k;fastcgi_busy_buffers_size 8k;fastcgi_temp_file_write_size 8k;fastcgi_cache TEST;fastcgi_cache_valid 200 302 1h;fastcgi_cache_valid 301 1d;fastcgi_cache_valid any 1m;fastcgi_cache_min_uses 1;fastcgi_cache_use_stale error timeout invalid_header http_500;open_file_cache max=204800 inactive=20s;open_file_cache_min_uses 1;open_file_cache_valid 30s;tcp_nodelay on;gzip on;gzip_min_length 1k;gzip_buffers 4 16k;gzip_http_version 1.0;gzip_comp_level 2;gzip_types text/plain application/x-javascript text/css application/xml;gzip_vary on;server{listen 8080;server_name backup.aiju.com;index index.php index.htm;root /www/html/;location /status{stub_status on;}location ~ ..(php|php5)?${fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fcgi.conf;}location ~ ..(gif|jpg|jpeg|png|bmp|swf|js|css)${expires 30d;}log_format access ‘$remote_addr – $remote_user [$time_local] “$request” ‘‘$status $body_bytes_sent “$http_referer” ‘‘“$http_user_agent” $http_x_forwarded_for’;access_log /www/log/access.log access;}}关于FastCGI 的几个指令：fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST:10minactive=5m;这个指令为FastCGI 缓存指定一个路径，目录结构等级，关键字区域存储时间和非活动删除时间。fastcgi_connect_timeout 300;指定连接到后端FastCGI 的超时时间。fastcgi_send_timeout 300;向FastCGI 传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI 传送请求的超时时间。fastcgi_read_timeout 300;接收FastCGI 应答的超时时间，这个值是指已经完成两次握手后接收FastCGI 应答的超时时间。fastcgi_buffer_size 4k;指定读取FastCGI 应答第一部分需要用多大的缓冲区，一般第一部分应答不会超过1k，由于页面大小为4k，所以这里设置为4k。fastcgi_buffers 8 4k;指定本地需要用多少和多大的缓冲区来缓冲FastCGI 的应答。fastcgi_busy_buffers_size 8k;这个指令我也不知道是做什么用，只知道默认值是fastcgi_buffers 的两倍。fastcgi_temp_file_write_size 8k;在写入fastcgi_temp_path 时将用多大的数据块，默认值是fastcgi_buffers 的两倍。fastcgi_cache TEST开启FastCGI 缓存并且为其制定一个名称。个人感觉开启缓存非常有用，可以有效降低CPU 负载，并且防止502 错误。fastcgi_cache_valid 200 302 1h;fastcgi_cache_valid 301 1d;fastcgi_cache_valid any 1m;为指定的应答代码指定缓存时间，如上例中将200，302 应答缓存一小时，301 应答缓存1 天，其他为1 分钟。fastcgi_cache_min_uses 1;缓存在fastcgi_cache_path 指令inactive 参数值时间内的最少使用次数，如上例，如果在5 分钟内某文件1 次也没有被使用，那么这个文件将被移除。fastcgi_cache_use_stale error timeout invalid_header http_500;不知道这个参数的作用，猜想应该是让nginx 知道哪些类型的缓存是没用的。以上为nginx 中FastCGI 相关参数，另外，FastCGI 自身也有一些配置需要进行优化，如果你使用php-fpm 来管理FastCGI，可以修改配置文件中的以下值：60同时处理的并发请求数，即它将开启最多60 个子线程来处理并发连接。102400最多打开文件数。204800每个进程在重置之前能够执行的最多请求数。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux用extundelete恢复ext2、ext3、ext4下rm -rf误删除的数据]]></title>
    <url>%2Flinuxyong-extundeletehui-fu-ext2-ext3-ext4xia-rm-rfwu-shan-chu-de-shu-ju%2F</url>
    <content type="text"><![CDATA[国外的Linux系统管理员守则中有这么一条：“慎用 rm -rf 命令，除非你知道此命令所带来的后果“Linux下删除文件并不是真实的删除磁盘分区中的文件，而是将文件的inode节点中的扇区指针清除，同时释放这些数据对应的数据块，当释放的数据块被系统重新分配时，那些被删除的数据就会被覆盖，所以误删除数据后，应马上卸载文件所在的分区。每个文件有inode和block组成，inode是文件系统组成的最基本单元，它保存着文件的基本属性(大小、权限、属主组等)和存放的位置信息。而block用来存储数据。类似key-value，inode就是key，block对应value，通过key查找key对应的value。类似python的字典。查看根目录的inode值12ls -id /2 /一般”根”目录的inode值为2,一个分区挂载到一个目录下时，这个”根”目录的inode值为2123mount /dev/sdb2 /mntls -id /mnt2 /mnt安装extundelete下载extundelete1wget http://ncu.dl.sourceforge.net/project/extundelete/extundelete/0.2.0/extundelete-0.2.0.tar.bz2所需依赖包1yum -y install e2fsprogs e2fsprogs-libs e2fsprogs-devel编译安装extundelte1234# tar jxvf extundelete-0.2.0.tar.bz2# cd extundelte-0.2.0# ./configure# make; make install用extundelete恢复文件模拟数据误删除环境123456789101112# mkdir /data# mkfs.ext4 /dev/sdb2# mount /dev/sdb2 /data# cp /etc/hosts /data/# mkdir /data/test# echo &quot;extundelete test&quot; &gt; /data/test/geek.txt# md5sum hosts #获取文件校验码54fb6627dbaa37721048e4549db3224d hosts# md5sum test/geek.txteb42e4b3f953ce00e78e11bf50652a80 test/geek.txt# rm -fr /data/*卸载磁盘分区1umount /dev/sdb2查询恢复数据信息1extundelete /dev/sdb2 --inode 2…..12345678File name | Inode number | Deleted statusDirectory block 8657:. 2.. 2lost+found 11 Deletedhosts 12 Deletedtest 130817 Deleted上面标记为Deleted是已经删除的文件或目录具体操作开始恢复单个文件默认恢复到当前目录下的RECOVERED_FILES目录中去1extundelete /dev/sdb2 --restore-file hosts恢复一个目录1extundelete /dev/sdb2 --restore-directory test/全部恢复1extundelete /dev/sdb2 --restore-all检测是否恢复成功1234# md5sum RECOVERED_FILES/hosts 获取文件校验码54fb6627dbaa37721048e4549db3224d RECOVERED_FILES/hosts# md5sum RECOVERED_FILES/test/geek.txteb42e4b3f953ce00e78e11bf50652a80 RECOVERED_FILES/test/geek.txt校验码与之前的完全一致。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>extundelete</tag>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ghost 加载慢问题分析]]></title>
    <url>%2Fghost-jia-zai-man-wen-ti-fen-xi%2F</url>
    <content type="text"><![CDATA[Ghost 搭建完能正常访问，可是墙内访问实在太慢了，按F12打开Chrome 开发者工具可以看到主要是 http://fonts.googleapis.com 这个访问使用了太长的时间。应该是GFW搞的鬼，使得 Google Fonts 服务也受影响了，Ghost 后台和默认主题都引用了 Google Fonts 服务，已至于每次打开自己的 Ghost 博客都很慢。这样我们就知道了问题的关键，马上登陆服务器，进入ghost目录。$ cd /data/www/ghost $ grep &apos;fonts.googleapis.com&apos; -n --color -r . 使用sed删除相应的行$ sudo sed -i &apos;19d&apos; ./content/themes/casper/default.hbs 上面修改的地方其实就是删除 Ghost 系统内引用的 Google Fonts 英文字体文件，这对于国内的用户丝毫没有影响，毕竟我们用的是 中文 嘛。经过修改，Google Fonts 文件就被彻底清除了。然后重启 Ghost 系统，再登录你的博客看看吧！$ sudo -i $ pm2 restart ghost]]></content>
      <tags>
        <tag>ghost</tag>
        <tag>google fonts</tag>
        <tag>sed</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保持文件原有排序去除重复行]]></title>
    <url>%2Fbao-chi-wen-jian-yuan-lai-pai-xu-qu-chu-zhong-fu-xing%2F</url>
    <content type="text"><![CDATA[通常如果我们想获取一个文件里不重复的行的时候，我们可以直接通过 sort -u 命令，先把文件排序，然后去掉连续的重复行就行。可是，如果我们去掉重复行之后，还想保留文件原有的顺序，该怎么办呢？虽然 Linux 下有个看上去似乎很有用的命令叫 uniq，但事实上 uniq 命令仅仅只对连续的重复行有效。譬如我们有这样一个文件：123456789$ cat file3AAAAFFFFBBBBBBBBCCCCAAAAFFFFDDDD如果不排序，直接使用 uniq 命令是没有用的：12345678$ uniq file3AAAAFFFFBBBBCCCCAAAAFFFFDDDD使用 sort -u 的话，我们就丢失了文件原有的行的顺序了：123456$ sort -u file3AAAABBBBCCCCDDDDFFFFsort 和 uniq 一起用，和 sort -u 效果是一样的：123456$ sort file3 | uniqAAAABBBBCCCCDDDDFFFF一个终极的解决方案是使用 awk：123456$ awk &apos; !x[$0]++&apos; file3AAAAFFFFBBBBCCCCDDDD简要解释一下，awk 的基本执行流程是，对文件的每一行，做一个指定的逻辑判断，如果逻辑判断成立，则执行指定的命令；如果逻辑判断不成立，则直接跳过这一行。我们这里写的 awk 命令是 !x[$0]++，意思是，首先创建一个 map 叫 x，然后用当前行的全文 $0 作为 map 的 key，到 map 中查找相应的 value，如果没找到，则整个表达式的值为真，可以执行之后的语句；如果找到了，则表达式的值为假，跳过这一行。由于表达式之后有 ++，因此如果某个 key 找不到对应的 value，该 ++ 操作会先把对应的 value 设成 0，然后再自增成 1，这样下次再遇到重复的行的时候，对应的 key 就能找到一个非 0 的 value 了。我们前面说过，awk 的流程是先判断表达式，表达式为真的时候就执行语句，可是我们前面写的这个 awk 命令里只有表达式，没有语句，那我们执行什么呢？原来，当语句被省略的时候，awk 就执行默认的语句，即打印整个完整的当前行。就这样，我们通过这个非常简短的 awk 命令实现了去除重复行并保留原有文件顺序的功能。引用本文部分翻译来自 Jadu Saikia 的博客，这个博客上有很多非常有用的小技巧，有空可以多看看。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>sed</tag>
        <tag>bash</tag>
        <tag>awk</tag>
        <tag>sort</tag>
        <tag>uniq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装配置Arch linux 相关]]></title>
    <url>%2Fan-zhuang-pei-zhi-arch-linux-xiang-guan%2F</url>
    <content type="text"><![CDATA[安装 linux-lts 软件包小贴士: 强烈推荐安装linux-lts作为备用内核，因为默认安装的linux内核比较新，容易与其它软件发生冲突linux-lts 是 Arch 官方提供的基于 Linux kernel 3.0 的长期支持内核。内核上游开发者针对此版本提供了长期支持，包括安全补丁和功能 backports。适用于需要长期支持的服务器环境用户，也可以将此内核作为新内核升级的后备内核。$ sudo pacman -S linux-lts配置启动需要编辑 GRUB2 或 LILO 的启动加载项。以 GRUB2 为例：为了编辑/更新启动加载项，需要安装os-prober.安装后,再执行$ sudo grub-mkconfig -o /boot/grub/grub.cfg]]></content>
      <tags>
        <tag>linux</tag>
        <tag>archlinux</tag>
        <tag>grub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux dd]]></title>
    <url>%2Flinux-dd%2F</url>
    <content type="text"><![CDATA[dd 是 Linux/UNIX 下的一个非常有用的命令，作用是用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。常用：dd 命令生成文件test.data 大小为1024M$ dd if=/dev/zero of=test.data bs=1024M count=1整盘数据备份与恢复将本地的/dev/sda1整盘备份到/dev/sda2$ dd if=/dev/sda1 of=/dev/sda2将/dev/sda2全盘数据备份到指定路径的image文件$ dd if=/dev/sda2 of=/path/to/image备份/dev/hdx全盘数据，并利用gzip工具进行压缩，保存到指定路径$ dd if=/dev/hdx | gzip &gt;/path/to/image.gz将备份文件恢复到指定盘：$ dd if=/path/to/image of=/dev/hdx将压缩的备份文件恢复到指定盘:$ gzip -dc /path/to/image.gz | dd of=/dev/hdx利用netcat远程备份在源主机上执行此命令备份/dev/hda$ dd if=/dev/hda bs=16065b | netcat &lt; targethost-IP &gt; 1234在目的主机上执行此命令来接收数据并写入/dev/hdc$ netcat -l -p 1234 | dd of=/dev/hdc bs=16065b以下两条指令是目的主机指令的变化分别采用bzip2 gzip对数据进行压缩，并将备份文件保存在当前目录。$ netcat -l -p 1234 | bzip2 &gt; partition.img $ netcat -l -p 1234 | gzip &gt; partition.img 备份MBR备份磁盘开始的512Byte大小的MBR信息到指定文件$ dd if=/dev/hdx of=/path/to/image count=1 bs=512将备份的MBR信息写到磁盘开始部分$ dd if=/path/to/image of=/dev/hdx磁盘管理#### 得到最恰当的block sizedd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.file dd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file dd if=/dev/zero bs=8192 count=125000 of=/root/1Gb.file 通过比较dd指令输出中所显示的命令执行时间，即可确定系统最佳的block size大小#### 测试硬盘读写速度$ dd if=/root/1Gb.file bs=64k | dd of=/dev/null $ dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000 通过上两个命令输出的执行时间，可以计算出测试硬盘的读／写速度#### 修复硬盘$ dd if=/dev/sda of=/dev/sda当硬盘较长时间（比如1，2年）放置不使用后，磁盘上会产生magnetic flux point。当磁头读到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一个扇区时，可能导致硬盘报废。上边的命令有可能使这些数据起死回生。且这个过程是安全，高效的。其他#### 将软驱数据备份到当前目录的disk.img文件dd if=/dev/fd0 of=disk.img count=1 bs=1440k#### 拷贝内存资料到硬盘$ dd if=/dev/mem of=/root/mem.bin bs=1024将内存里的数据拷贝到root目录下的mem.bin文件#### 从光盘拷贝iso镜像$ dd if=/dev/cdrom of=/root/cd.iso拷贝光盘数据到root文件夹下，并保存为cd.iso文件#### 增加Swap分区文件大小$ dd if=/dev/zero of=/swapfile bs=1024 count=262144创建一个足够大的文件（此处为256M）$ mkswap /swapfile把这个文件变成swap文件$ swapon /swapfile启用这个swap文件$ /swapfile swap swap defaults 0 0在每次开机的时候自动加载swap文件, 需要在 /etc/fstab 文件中增加一行#### 销毁磁盘数据$ dd if=/dev/urandom of=/dev/hda1利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。执行此操作以后，/dev/hda1将无法挂载，创建和拷贝操作无法执行。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>dd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 加解密打包文件]]></title>
    <url>%2Fshi-yong-taryu-openssljia-mi-jie-mi-da-bao-wen-jian%2F</url>
    <content type="text"><![CDATA[预备知识使用到的命令有tar,openssl,dd$ mkdir test_dir; cd test_dir/ ; touch test.file; cd .. ; ll test_dir/-rw-r–r– 1 hcaijin hcaijin 0 4月 30 16:35 test.file$ tar -zcvf - test_dir/ | openssl des3 -salt -k password | dd of=test_dir.tagtest_dir/test_dir/test.file记录了0+1 的读入记录了0+1 的写出176字节(176 B)已复制，0.0114724 秒，15.3 kB/秒$ dd if=test_dir.tag | openssl des3 -d -k password | tar -zxvf -记录了0+1 的读入记录了0+1 的写出176字节(176 B)已复制，0.000495166 秒，355 kB/秒test_dir/test_dir/test.file详细openssl 可查看帮助页$ man openssl $ openssl enc -hopenssl 命令详解SYNOPSIS openssl enc -ciphername [-in filename] [-out filename] [-pass arg] [-e] [-d] [-a] [-A] [-k password] [-kfile filename] [-K key] [-iv IV] [-p] [-P] [-bufsize number] [-nopad] [-debug] 说明： -chipername选项：加密算法，Openssl支持的算法在上面已经列出了，你只需选择其中一种算法即可实现文件加密功能。 -in选项：输入文件，对于加密来说，输入的应该是明文文件；对于解密来说，输入的应该是加密的文件。该选项后面直接跟文件名。 -out选项：输出文件，对于加密来说，输出的应该是加密后的文件名；对于解密来说，输出的应该是明文文件名。 -pass选项：选择输入口令的方式，输入源可以是标准输入设备，命令行输入，文件、变量等。 -e选项：实现加密功能（不使用-d选项的话默认是加密选项）。 -d选项：实现解密功能。 -a和-A选项：对文件进行BASE64编解码操作。 -K选项：手动输入加密密钥（不使用该选项，Openssl会使用口令自动提取加密密钥）。 -IV选项：输入初始变量（不使用该选项，Openssl会使用口令自动提取初始变量）。 -salt选项：是否使用盐值，默认是使用的。 -p选项：打印出加密算法使用的加密密钥。加密举例：$ openssl enc -aes-128-cbc -in pacman.log -out pacman.log.aesenter aes-128-cbc encryption password: **Verifying - enter aes-128-cbc encryption password: *以上执行成功，生成加密文件 pacman.log.base64，使用以下命令解密：$ openssl enc -d -aes-128-cbc -in pacman.log.aes -out pacman.out.logenter aes-128-cbc decryption password: **下面方法的好处是你可以把它写入到脚本中，自动完成加密功能，不使用pass选项默认系统会提示输入密码并且确认，是需要人工操作的。$ openssl enc -aes-256-ecb -in pacman.log -out pacman.aes256.log -pass pass:123456 $ file pacman.aes256.logpacman.aes256.log: data$ openssl enc -d -aes-256-ecb -out pacman256.log -in pacman.aes256.logenter aes-256-ecb decryption password:$ file pacman256.logpacman256.log: UTF-8 Unicode text生成 pacman256.log 可以用file 看到文件解密为原来的类型了]]></content>
      <tags>
        <tag>linux</tag>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装 node.js ghost 相关总结]]></title>
    <url>%2Fan-zhuang-ghostxiang-guan-zong-jie%2F</url>
    <content type="text"><![CDATA[下载安装安装node.js 下载最新node.js 编译安装需要一段时间。$ wget http://nodejs.org/dist/node-latest.tar.gz $ tar -xzf node-latest.tar.gz $ cd node-v $ ./configure $ make $ sudo make install 安装Ghost安装扩展$ yum install gcc-c++ghost下载，安装$ sudo mkdir -p /data/www/ $ cd /data/www/ $ wget https://ghost.org/zip/ghost-latest.zip $ unzip -d ghost ghost-latest.zip $ cd /var/www/ghost $ sudo npm install --production 安装完成后用 npm start 命令启动开发者模式下的 Ghost，用于检查有没有安装成功。 成功了，Ghost会运行在本地局域网内 127.0.0.1:2368。如果是在电脑上安装的，用浏览器访问此地址即可预览 Ghost。安装pm2安装强大的进程守护程序“PM2”保证应用在开机以后自动启动进入到/data/www/ghost，执行命令安装PM2：$ sudo npm install pm2 -g设置环境变量为“production”生产模式，“index.js”是程序启动的入口。最后给这个PM2的进程命名为”ghost” 执行下面的命令：$ NODE_ENV=production pm2 start index.js --name &quot;ghost&quot;设置开机自动运行网站：$ pm2 startup centos $ pm2 save可以执行 pm2 help 查看帮助。配置nginx配置 Nginx 的反向代理：新建一个 Nginx 代理配置文件,并将代理指向到本地的Ghost端口:$ sudo vim /etc/nginx/conf.d/ghost.conf` server { listen 80; server_name My-Ghost-Blog.com; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; } } 重新启动 Nginx 服务器.$ sudo service nginx restart注意事项修改服务器时间，这样新增的文章才能显示正常的本地时间 。$ sudo yun install -y ntp $ sudo cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ghost</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
</search>
